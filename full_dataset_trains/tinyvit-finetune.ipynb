{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "130095c9-7341-4a68-9468-55180d2dd817",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'first_try'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82500098-49ea-4a7e-bb63-ce5130f954cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>is_tma</th>\n",
       "      <th>tile_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>23785</td>\n",
       "      <td>20008</td>\n",
       "      <td>False</td>\n",
       "      <td>../tiles_768/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>LGSC</td>\n",
       "      <td>48871</td>\n",
       "      <td>48195</td>\n",
       "      <td>False</td>\n",
       "      <td>../tiles_768/66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>3388</td>\n",
       "      <td>3388</td>\n",
       "      <td>True</td>\n",
       "      <td>../tiles_768/91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>281</td>\n",
       "      <td>LGSC</td>\n",
       "      <td>42309</td>\n",
       "      <td>15545</td>\n",
       "      <td>False</td>\n",
       "      <td>../tiles_768/281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>286</td>\n",
       "      <td>EC</td>\n",
       "      <td>37204</td>\n",
       "      <td>30020</td>\n",
       "      <td>False</td>\n",
       "      <td>../tiles_768/286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id label  image_width  image_height  is_tma         tile_path\n",
       "0         4  HGSC        23785         20008   False    ../tiles_768/4\n",
       "1        66  LGSC        48871         48195   False   ../tiles_768/66\n",
       "2        91  HGSC         3388          3388    True   ../tiles_768/91\n",
       "3       281  LGSC        42309         15545   False  ../tiles_768/281\n",
       "4       286    EC        37204         30020   False  ../tiles_768/286"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_image_path(image_id:int):\n",
    "    return os.path.join('../tiles_768', str(image_id))\n",
    "\n",
    "train = pd.read_csv(f\"../data/train.csv\")\n",
    "\n",
    "train['tile_path'] = train['image_id'].apply(lambda x: get_image_path(x))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d782638-2c6c-4b63-87b3-c7bf291bbde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda and model timm/tiny_vit_21m_224.dist_in22k_ft_in1k\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from timm.models.layers import DropPath\n",
    "import copy\n",
    "from itertools import cycle\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"timm/tiny_vit_21m_224.dist_in22k_ft_in1k\"\n",
    "\n",
    "print(f\"Using device {device} and model {model_name}\")\n",
    "\n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "# drop_path_rate = 0.1\n",
    "dropout_rate = 0.1\n",
    "# drop_path_rates = []\n",
    "# total_blocks = 0\n",
    "# for stage in model.stages:\n",
    "#     if hasattr(stage, 'blocks'):\n",
    "#         for block in stage.blocks:\n",
    "#             total_blocks += 1\n",
    "# drop_path_rates = [x.item() for x in torch.linspace(0, drop_path_rate, total_blocks)]\n",
    "        \n",
    "i_drop = 0\n",
    "# Assign drop path rates\n",
    "for stage in model.stages:\n",
    "    if hasattr(stage, 'blocks'):\n",
    "        for block in stage.blocks:\n",
    "            # block.drop_path = DropPath(drop_prob=drop_path_rates[i_drop])\n",
    "            # block.drop_path1 = DropPath(drop_prob=drop_path_rates[i_drop])\n",
    "            # block.drop_path2 = DropPath(drop_prob=drop_path_rates[i_drop])\n",
    "            if hasattr(block, 'mlp'):\n",
    "                block.mlp.drop1 = nn.Dropout(p=dropout_rate, inplace=False)\n",
    "                block.mlp.drop2 = nn.Dropout(p=dropout_rate, inplace=False)\n",
    "            \n",
    "            i_drop += 1\n",
    "\n",
    "model.head.drop = nn.Dropout(p=dropout_rate, inplace=False)\n",
    "model.head.fc = nn.Linear(model.head.in_features, 5)\n",
    "state_dict = torch.load('tinyvit_models_first_try/epoch_0_step_4000.pth', map_location=device)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize EMA model\n",
    "ema_decay = 0.999  # decay factor for EMA\n",
    "ema_model = copy.deepcopy(model)\n",
    "ema_model = ema_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9613dea-4edf-47cd-a042-5f3468b19d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "integer_to_label = {\n",
    "    0: 'HGSC',\n",
    "    1: 'CC',\n",
    "    2: 'EC',\n",
    "    3: 'LGSC',\n",
    "    4: 'MC',\n",
    "}\n",
    "\n",
    "label_to_integer = {\n",
    "    'HGSC': 0,\n",
    "    'CC': 1,\n",
    "    'EC': 2,\n",
    "    'LGSC': 3,\n",
    "    'MC': 4,\n",
    "}\n",
    "    \n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.all_images = []  # Store all images in an interlaced fashion\n",
    "        self.folder_images = []  # Temporary storage for images from each folder\n",
    "\n",
    "        # Step 1: Collect all images from each folder\n",
    "        for index, row in dataframe.iterrows():\n",
    "            folder_path = row['tile_path']\n",
    "            label = row['label']\n",
    "            image_id = row['image_id']\n",
    "            if os.path.isdir(folder_path):\n",
    "                image_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.lower().endswith('.png')]\n",
    "                random.shuffle(image_files)\n",
    "                self.folder_images.append([(image_file, label, image_id) for image_file in image_files])\n",
    "\n",
    "        # Step 2: Interlace the images\n",
    "        max_length = max(len(images) for images in self.folder_images)\n",
    "        for i in range(max_length):\n",
    "            for images in self.folder_images:\n",
    "                self.all_images.append(images[i % len(images)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label, image_id = self.all_images[idx]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label_to_integer[label], image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daab3db2-8fff-4b14-83f9-608c256dea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.75, 1.0), ratio=(0.75, 1.33)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=(0, 360)),\n",
    "    transforms.RandomAffine(degrees=0, shear=(-20, 20, -20, 20)),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.3, hue=0.3),\n",
    "    transforms.RandomApply([transforms.Grayscale(num_output_channels=3)], p=0.25),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 1))], p=0.25),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[\n",
    "        0.485,\n",
    "        0.456,\n",
    "        0.406\n",
    "    ], std=[\n",
    "        0.229,\n",
    "        0.224,\n",
    "        0.225\n",
    "    ]),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[\n",
    "        0.485,\n",
    "        0.456,\n",
    "        0.406\n",
    "    ], std=[\n",
    "        0.229,\n",
    "        0.224,\n",
    "        0.225\n",
    "    ]),\n",
    "])\n",
    "\n",
    "train_dataset = ImageDataset(dataframe=train, transform=train_transform)\n",
    "\n",
    "# Calculate weights for each class\n",
    "class_counts = [train.groupby('label').count().loc[label]['image_id'] for label in label_to_integer]  # Example class counts\n",
    "num_samples = sum(class_counts)\n",
    "class_weights = [num_samples / class_count for class_count in class_counts]\n",
    "\n",
    "# Assign a weight to each sample in the dataset based on its class\n",
    "sample_weights = [class_weights[label_to_integer[label]] for _, label, _ in train_dataset.all_images]\n",
    "\n",
    "# Create WeightedRandomSampler\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# DataLoader with WeightedRandomSampler\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa0e2bd-4c21-48a1-a0fe-5eb15fb556b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Get the root logger\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Optional: Remove all existing handlers from the logger\n",
    "for handler in logger.handlers[:]:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "# Set the logging level\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create a FileHandler and add it to the logger\n",
    "file_handler = logging.FileHandler(f'logs/tinyvit_train_{MODEL_NAME}.txt')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Create a StreamHandler for stderr and add it to the logger\n",
    "stream_handler = logging.StreamHandler(sys.stderr)\n",
    "stream_handler.setLevel(logging.ERROR)  # Only log ERROR and CRITICAL messages to stderr\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9b938-9860-4147-be7e-f6f36938f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import random\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "initial_lr = 0.0005 * BATCH_SIZE/1024\n",
    "final_lr = initial_lr * 0.01\n",
    "num_epochs = 10000\n",
    "\n",
    "# Function for linear warmup\n",
    "def learning_rate(step, warmup_steps=1000, max_steps=10000):\n",
    "    if step < warmup_steps:\n",
    "        return initial_lr * (float(step) / float(max(1, warmup_steps)))\n",
    "    elif step < max_steps:\n",
    "        progress = (float(step - warmup_steps) / float(max(1, max_steps - warmup_steps)))\n",
    "        cos_component = 0.5 * (1 + math.cos(math.pi * progress))\n",
    "        return final_lr + (initial_lr - final_lr) * cos_component\n",
    "    else:\n",
    "        return final_lr\n",
    "\n",
    "def update_ema_variables(model, ema_model, alpha):\n",
    "    # Update the EMA model parameters\n",
    "    with torch.no_grad():\n",
    "        for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
    "            ema_param.data.mul_(alpha).add_(param.data, alpha=1 - alpha)\n",
    "\n",
    "scaler = GradScaler()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=initial_lr, weight_decay=1e-8)\n",
    "\n",
    "# Define the loss function with class weights\n",
    "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "best_val_accuracy = 0.0\n",
    "step = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # set the model to training mode\n",
    "    \n",
    "    for i, (images, labels, _) in enumerate(train_dataloader, 0):\n",
    "        # Convert images to PIL format\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Linearly increase the learning rate\n",
    "        lr = learning_rate(step)\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = lr\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass with autocast\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            logits_per_image = outputs\n",
    "            loss = criterion(logits_per_image, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        update_ema_variables(model, ema_model, ema_decay)\n",
    "\n",
    "        logging.info('[%d, %5d] loss: %.3f' % (epoch + 1, step, loss.item()))\n",
    "\n",
    "        if step % 500 == 0:\n",
    "            ema_model.eval()\n",
    "            torch.save(ema_model.state_dict(), f'tinyvit_models_{MODEL_NAME}/epoch_{epoch}_step_{step}.pth')\n",
    "            logging.info(f'Model saved after epoch {epoch} and step {step}')\\\n",
    "\n",
    "            model.train()\n",
    "\n",
    "        if step == 10000:\n",
    "            torch.save(ema_model.state_dict(), f'tinyvit_models_{MODEL_NAME}/final.pth')\n",
    "            break\n",
    "    \n",
    "        step += 1\n",
    "        \n",
    "    if step >= 10000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02074fd9-314d-47c1-97be-b73dcdb26d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def duplicate_ipynb_with_new_name(src_file_path, dest_dir, new_name):\n",
    "    \"\"\"\n",
    "    Duplicate an IPython notebook file to a new directory with a new file name.\n",
    "\n",
    "    Parameters:\n",
    "    src_file_path (str): The path of the source IPython notebook file.\n",
    "    dest_dir (str): The destination directory where the file will be copied.\n",
    "    new_name (str): The new file name for the duplicated notebook.\n",
    "\n",
    "    Returns:\n",
    "    str: The path of the duplicated file with the new name.\n",
    "    \"\"\"\n",
    "    # Check if the new name contains the '.ipynb' extension, add if not\n",
    "    if not new_name.endswith('.ipynb'):\n",
    "        new_name += '.ipynb'\n",
    "\n",
    "    # Creating the destination file path with the new name\n",
    "    dest_file_path = os.path.join(dest_dir, new_name)\n",
    "\n",
    "    # Copying the file to the new directory\n",
    "    shutil.copy(src_file_path, dest_file_path)\n",
    "\n",
    "    return dest_file_path\n",
    "\n",
    "src_file = \"eva02-base-finetune.ipynb\"\n",
    "dest_directory = \"notebook_history\"\n",
    "new_filename = f\"{MODEL_NAME}.ipynb\"\n",
    "duplicate_ipynb_with_new_name(src_file, dest_directory, new_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de1a4c8-de5e-49c6-84ff-fab37a0329f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 5]) HGSC 4 HGSC tensor([ 0.3912,  0.1024,  0.2623,  0.1081, -0.8786], device='cuda:0')\n",
      "torch.Size([32, 5]) LGSC 66 HGSC tensor([ 0.3081,  0.1374,  0.2456,  0.1123, -0.6771], device='cuda:0')\n",
      "torch.Size([18, 5]) HGSC 91 HGSC tensor([ 0.9344, -0.3207,  0.2798, -0.0508, -0.6196], device='cuda:0')\n",
      "torch.Size([32, 5]) LGSC 281 EC tensor([ 0.3054, -0.0984,  0.3649, -0.1066, -0.3939], device='cuda:0')\n",
      "torch.Size([32, 5]) EC 286 EC tensor([ 0.4677, -0.3240,  1.1658, -0.6466, -0.2813], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 431 CC tensor([ 0.2733,  0.3486,  0.1957, -0.3043, -0.5536], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 706 HGSC tensor([ 0.5510, -0.3401,  0.4300, -0.3161, -0.1999], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 970 EC tensor([ 0.0111,  0.0716,  0.2086,  0.1667, -0.4613], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 1020 EC tensor([ 0.5111,  0.0762,  0.6344, -0.3561, -0.8774], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 1080 EC tensor([ 0.4158, -0.0538,  0.5244, -0.1019, -0.6805], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 1101 HGSC tensor([ 1.0546, -0.5663,  0.4516, -0.3631, -0.5864], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 1252 HGSC tensor([ 0.6438, -0.1257,  0.2760, -0.4232, -0.2051], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 1289 EC tensor([ 0.1173,  0.2165,  0.5357, -0.3185, -0.3870], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 1295 EC tensor([ 0.7117, -0.3833,  0.9556, -1.4229,  0.5153], device='cuda:0')\n",
      "torch.Size([32, 5]) CC 1660 CC tensor([-0.0495,  1.1176, -0.0117, -0.7008, -0.6618], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 1666 HGSC tensor([ 1.0260,  0.0588,  0.3577, -0.9243, -0.6540], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 1774 CC tensor([-0.0116,  0.6497,  0.1991, -0.7935, -0.1775], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 1925 HGSC tensor([ 0.6447,  0.1506,  0.1039, -0.3705, -0.6852], device='cuda:0')\n",
      "torch.Size([32, 5]) CC 1943 EC tensor([ 0.2943,  0.3306,  0.4647, -0.4567, -0.6803], device='cuda:0')\n",
      "torch.Size([32, 5]) CC 1952 CC tensor([-6.1810e-01,  2.0253e+00,  1.5442e-04, -1.2681e+00, -6.0089e-01],\n",
      "       device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 2097 LGSC tensor([ 0.1972, -0.0569,  0.1097,  0.4732, -0.7426], device='cuda:0')\n",
      "torch.Size([32, 5]) MC 2227 EC tensor([ 0.3905, -0.2211,  0.8644, -0.9008,  0.1183], device='cuda:0')\n",
      "torch.Size([32, 5]) LGSC 2391 LGSC tensor([-0.1387, -0.0926, -0.0518,  1.2018, -0.8657], device='cuda:0')\n",
      "torch.Size([32, 5]) EC 2666 HGSC tensor([ 0.7237, -0.1137,  0.4837, -0.7676, -0.3615], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 2706 HGSC tensor([ 1.3332, -0.5140,  0.2328, -0.1447, -0.8306], device='cuda:0')\n",
      "torch.Size([32, 5]) EC 2906 EC tensor([ 0.3617,  0.0549,  0.7310, -0.8426, -0.3248], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 3055 EC tensor([ 0.5620, -0.3072,  0.8022, -0.5775, -0.2914], device='cuda:0')\n",
      "torch.Size([32, 5]) MC 3084 MC tensor([-0.2784,  0.0250,  0.2775, -0.7690,  0.9115], device='cuda:0')\n",
      "torch.Size([32, 5]) LGSC 3092 LGSC tensor([ 0.2165, -0.0132,  0.0422,  0.6754, -0.7914], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 3098 HGSC tensor([ 0.7256,  0.0226,  0.6808, -1.1015, -0.3234], device='cuda:0')\n",
      "torch.Size([32, 5]) CC 3191 CC tensor([-0.2525,  1.6870, -0.1237, -0.8807, -0.8505], device='cuda:0')\n",
      "torch.Size([32, 5]) EC 3222 LGSC tensor([ 0.2521, -0.2330,  0.2435,  0.6311, -0.6754], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 3264 HGSC tensor([ 0.7137,  0.1272,  0.5953, -1.0524, -0.4902], device='cuda:0')\n",
      "torch.Size([32, 5]) EC 3511 HGSC tensor([ 0.5081, -0.1543,  0.3242,  0.0576, -0.7683], device='cuda:0')\n",
      "torch.Size([32, 5]) LGSC 3672 LGSC tensor([ 0.3920,  0.1162, -0.2656,  0.6993, -0.9317], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 3881 HGSC tensor([ 0.3514, -0.0554,  0.2627,  0.1656, -0.8335], device='cuda:0')\n",
      "torch.Size([32, 5]) MC 3997 EC tensor([ 0.0400, -0.0292,  0.3560, -0.6452,  0.3454], device='cuda:0')\n",
      "torch.Size([15, 5]) MC 4134 CC tensor([-0.0943,  0.4385,  0.3913, -1.0673,  0.1629], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 4211 HGSC tensor([ 0.6774,  0.0207,  0.3470, -0.7832, -0.2104], device='cuda:0')\n",
      "torch.Size([32, 5]) EC 4608 EC tensor([ 0.0224, -0.0072,  0.9693, -0.3714, -0.5268], device='cuda:0')\n",
      "torch.Size([32, 5]) MC 4797 MC tensor([-0.1092, -0.2204,  0.5470, -0.9053,  0.8172], device='cuda:0')\n",
      "torch.Size([32, 5]) CC 4827 CC tensor([-0.4944,  1.7290,  0.0959, -1.1225, -0.5423], device='cuda:0')\n",
      "torch.Size([32, 5]) CC 4877 CC tensor([-0.2094,  1.8754, -0.0438, -0.9885, -0.7983], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 4963 EC tensor([ 0.8571, -0.0647,  0.9122, -0.9866, -0.7805], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 5015 HGSC tensor([ 0.6431, -0.1407,  0.3734, -0.1511, -0.7261], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 5114 HGSC tensor([ 1.0085, -0.0731,  0.5055, -1.0228, -0.5257], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 5251 HGSC tensor([ 1.0247, -0.1831,  0.3529, -0.7053, -0.6243], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 5264 HGSC tensor([ 0.5677, -0.2711,  0.3598,  0.0017, -0.5228], device='cuda:0')\n",
      "torch.Size([32, 5]) EC 5265 EC tensor([ 0.1959, -0.2049,  1.0387, -0.9043,  0.1693], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 5307 EC tensor([ 0.2668,  0.1892,  0.3715, -0.9554,  0.0042], device='cuda:0')\n",
      "torch.Size([32, 5]) MC 5456 MC tensor([-0.3124, -0.0923,  0.5030, -0.7484,  0.9355], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 5851 HGSC tensor([ 1.1606, -0.2533,  0.1230, -0.2748, -0.7253], device='cuda:0')\n",
      "torch.Size([32, 5]) LGSC 5852 LGSC tensor([ 0.3429, -0.1911, -0.0863,  0.6770, -0.8036], device='cuda:0')\n",
      "torch.Size([32, 5]) CC 5970 CC tensor([-0.1988,  1.0717,  0.1907, -0.5189, -0.6705], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 5992 HGSC tensor([ 1.0949, -0.3813,  0.4096, -0.6439, -0.5199], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 6140 HGSC tensor([ 1.3513, -0.3214,  0.5945, -0.9790, -0.6073], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 6175 HGSC tensor([ 0.7814, -0.0108,  0.5174, -0.9365, -0.4073], device='cuda:0')\n",
      "torch.Size([32, 5]) EC 6281 EC tensor([ 0.1419, -0.1267,  0.7140, -0.4879, -0.2365], device='cuda:0')\n",
      "torch.Size([32, 5]) CC 6359 CC tensor([ 0.0051,  0.9910,  0.2432, -1.1587, -0.3843], device='cuda:0')\n",
      "torch.Size([32, 5]) EC 6363 CC tensor([ 0.0713,  0.4654,  0.4286, -0.6237, -0.2946], device='cuda:0')\n",
      "torch.Size([32, 5]) CC 6449 CC tensor([-0.1426,  1.0776,  0.3325, -1.2034, -0.3019], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 6558 HGSC tensor([ 0.9892, -0.2050,  0.1207, -0.2834, -0.5090], device='cuda:0')\n",
      "torch.Size([32, 5]) MC 6582 MC tensor([-0.2173,  0.1464,  0.1418, -0.9195,  0.8891], device='cuda:0')\n",
      "torch.Size([32, 5]) EC 6793 EC tensor([ 0.2895, -0.0775,  1.1768, -1.2021, -0.0040], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 6843 HGSC tensor([ 0.6827,  0.2259,  0.4518, -0.7446, -0.8028], device='cuda:0')\n",
      "torch.Size([32, 5]) LGSC 6898 LGSC tensor([-0.1570,  0.3111, -0.2174,  0.8997, -0.6986], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 6951 HGSC tensor([ 1.1105, -0.1165,  0.0183, -0.5563, -0.5075], device='cuda:0')\n",
      "torch.Size([32, 5]) EC 7204 EC tensor([ 0.1125, -0.1437,  0.6954, -0.1764, -0.5188], device='cuda:0')\n",
      "torch.Size([32, 5]) EC 7329 EC tensor([ 0.5279,  0.0320,  0.5444, -1.1055, -0.0389], device='cuda:0')\n",
      "torch.Size([32, 5]) CC 7482 CC tensor([-0.0516,  1.0540, -0.1760, -0.3655, -0.5504], device='cuda:0')\n",
      "torch.Size([32, 5]) EC 7490 CC tensor([-0.0305,  1.0545,  0.3464, -1.0882, -0.5866], device='cuda:0')\n",
      "torch.Size([32, 5]) CC 7955 CC tensor([-0.3839,  1.7785, -0.2965, -0.9108, -0.7985], device='cuda:0')\n",
      "torch.Size([32, 5]) LGSC 8130 LGSC tensor([ 0.2959,  0.2377,  0.0812,  0.3418, -0.9409], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 8213 HGSC tensor([ 1.0198, -0.2008,  0.2707, -0.7824, -0.4711], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 8240 HGSC tensor([ 1.2929, -0.3454,  0.3078, -0.5048, -0.7793], device='cuda:0')\n",
      "torch.Size([32, 5]) CC 8279 CC tensor([-0.0826,  1.2706,  0.0091, -0.7688, -0.6160], device='cuda:0')\n",
      "torch.Size([16, 5]) HGSC 8280 HGSC tensor([ 0.9760,  0.0768, -0.2191, -0.1090, -0.9380], device='cuda:0')\n",
      "torch.Size([32, 5]) EC 8531 EC tensor([ 0.2772, -0.3682,  1.1600, -0.4554, -0.5475], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 8713 HGSC tensor([ 0.7968, -0.1927,  0.0969, -0.3121, -0.4264], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 8805 HGSC tensor([ 0.8067, -0.0041,  0.2711, -0.6075, -0.5185], device='cuda:0')\n",
      "torch.Size([32, 5]) LGSC 8985 EC tensor([ 0.1007, -0.0219,  0.2741,  0.1582, -0.3970], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 9154 EC tensor([ 0.1024,  0.1932,  0.2380, -0.3846, -0.2637], device='cuda:0')\n",
      "torch.Size([32, 5]) LGSC 9183 LGSC tensor([-0.0954,  0.1663, -0.2249,  0.8466, -0.5000], device='cuda:0')\n",
      "torch.Size([15, 5]) MC 9200 MC tensor([-0.3713,  0.1697,  0.6317, -1.1105,  0.9037], device='cuda:0')\n",
      "torch.Size([32, 5]) MC 9254 MC tensor([-0.2936,  0.1259,  0.5023, -0.6899,  0.5588], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 9341 HGSC tensor([ 0.6275, -0.1162,  0.3772, -0.1631, -0.5463], device='cuda:0')\n",
      "torch.Size([32, 5]) HGSC 9509 EC tensor([ 0.3740,  0.1017,  0.4924, -0.4631, -0.7395], device='cuda:0')\n",
      "torch.Size([32, 5]) CC 9658 CC tensor([-0.2897,  1.7698,  0.0856, -1.0904, -0.5979], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "ema_model.eval()\n",
    "\n",
    "image_ids = []\n",
    "logits = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _, row in train.iterrows():\n",
    "        path = row['tile_path']\n",
    "        all_files = [f for f in os.listdir(path) if f.lower().endswith('.png')]\n",
    "\n",
    "        sum_probabilities = torch.zeros(5).to(device)\n",
    "        sum_log_probabilities = torch.zeros(5).to(device)\n",
    "        sum_log_neg_probabilities = torch.zeros(5).to(device)\n",
    "        \n",
    "        batch_logits = []\n",
    "\n",
    "        # Prepare a list to hold image tiles\n",
    "        batch_tiles = []\n",
    "\n",
    "        sample_size = min(32, len(all_files))\n",
    "        sampled_files = random.sample(all_files, sample_size)\n",
    "\n",
    "        for image_name in sampled_files:\n",
    "            image_path = os.path.join(path, image_name)\n",
    "            sub_image = Image.open(image_path)\n",
    "\n",
    "            tile = val_transform(sub_image).unsqueeze(0).to(device)\n",
    "            batch_tiles.append(tile)\n",
    "        \n",
    "        for i_batch in range(0, len(batch_tiles), 32):\n",
    "            outputs = ema_model(torch.concat(batch_tiles[i_batch:i_batch+32], dim=0))\n",
    "            probs = outputs.softmax(dim=1)\n",
    "            batch_logits.append(outputs)\n",
    "            sum_probabilities += probs.sum(dim=0)\n",
    "            sum_log_probabilities += torch.log(probs).sum(dim=0)\n",
    "            sum_log_neg_probabilities += torch.log(1 - probs).sum(dim=0)\n",
    "        \n",
    "        image_id = row['image_id']\n",
    "        batch_logits = torch.concat(batch_logits, dim=0)\n",
    "        mean_logits = batch_logits.mean(dim=0)\n",
    "        label = row['label']\n",
    "        print(batch_logits.shape, label, image_id, integer_to_label[mean_logits.argmax().cpu().item()], mean_logits)\n",
    "        image_ids.append(image_id)\n",
    "        logits.append(batch_logits)\n",
    "        labels.append(label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef7a99a1-3df6-4b4e-8259-d8fe855119f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7246153846153847"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "for image_logits in logits:\n",
    "    summed_logits = image_logits.sum(dim=0)\n",
    "    \n",
    "    max_vote_key = summed_logits.argmax().cpu().item()\n",
    "    predictions.append(integer_to_label[max_vote_key])\n",
    "\n",
    "logit_sum_accuracy = balanced_accuracy_score(labels, predictions)\n",
    "logit_sum_accuracy"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m114"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

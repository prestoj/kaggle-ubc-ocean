{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82500098-49ea-4a7e-bb63-ce5130f954cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>is_tma</th>\n",
       "      <th>tile_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>23785</td>\n",
       "      <td>20008</td>\n",
       "      <td>False</td>\n",
       "      <td>../tiles_768/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>LGSC</td>\n",
       "      <td>48871</td>\n",
       "      <td>48195</td>\n",
       "      <td>False</td>\n",
       "      <td>../tiles_768/66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>3388</td>\n",
       "      <td>3388</td>\n",
       "      <td>True</td>\n",
       "      <td>../tiles_768/91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>281</td>\n",
       "      <td>LGSC</td>\n",
       "      <td>42309</td>\n",
       "      <td>15545</td>\n",
       "      <td>False</td>\n",
       "      <td>../tiles_768/281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>286</td>\n",
       "      <td>EC</td>\n",
       "      <td>37204</td>\n",
       "      <td>30020</td>\n",
       "      <td>False</td>\n",
       "      <td>../tiles_768/286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id label  image_width  image_height  is_tma         tile_path\n",
       "0         4  HGSC        23785         20008   False    ../tiles_768/4\n",
       "1        66  LGSC        48871         48195   False   ../tiles_768/66\n",
       "2        91  HGSC         3388          3388    True   ../tiles_768/91\n",
       "3       281  LGSC        42309         15545   False  ../tiles_768/281\n",
       "4       286    EC        37204         30020   False  ../tiles_768/286"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_image_path(image_id:int):\n",
    "    return os.path.join('../tiles_768', str(image_id))\n",
    "\n",
    "# train = pd.read_csv(f\"../data/train.csv\")\n",
    "train = pd.read_csv(f\"train_fold_1.csv\")\n",
    "\n",
    "train['tile_path'] = train['image_id'].apply(lambda x: get_image_path(x))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b605580-268b-42c0-a374-3adae0ce9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.models.vision_transformer import Block\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class GlobalModel(nn.Module):\n",
    "    def __init__(self, n_heads, n_layers, embed_dim, n_classes):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.n_layers = n_layers\n",
    "        self.embed_dim = embed_dim\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        drop_path_rate = 0.0\n",
    "        drop_out_rate = 0.0\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.patch_embed = nn.Linear(768, embed_dim)\n",
    "        self.norm_pre = nn.LayerNorm(embed_dim)\n",
    "        self.drop_pre = nn.Dropout(p=drop_out_rate)\n",
    "        \n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, n_layers)]\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            Block(\n",
    "                dim=embed_dim,\n",
    "                num_heads=n_heads,\n",
    "                proj_drop=drop_out_rate,\n",
    "                attn_drop=drop_out_rate,\n",
    "                drop_path=dpr[i]\n",
    "            )\n",
    "            for i in range(n_layers)])\n",
    "        self.norm_post = nn.LayerNorm(embed_dim)\n",
    "        self.head_drop = nn.Dropout(p=drop_out_rate)\n",
    "        self.fc_head = nn.Linear(embed_dim, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        x = torch.cat([self.cls_token.expand(x.shape[0], -1, -1), x], dim=1)\n",
    "        \n",
    "        x = self.norm_pre(x)\n",
    "        x = self.drop_pre(x)\n",
    "        x = self.blocks(x)\n",
    "        \n",
    "        x = x[:, 1:].mean(dim=1)\n",
    "        x = self.norm_post(x)\n",
    "        x = self.head_drop(x)\n",
    "        x = self.fc_head(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# global_model = GlobalModel(n_heads=3, n_layers=12, embed_dim=192, n_classes=5) # second third fourth\n",
    "# global_model = GlobalModel(n_heads=12, n_layers=1, embed_dim=768, n_classes=5) # fifth\n",
    "global_model = GlobalModel(n_heads=3, n_layers=1, embed_dim=192, n_classes=5) # sixth seventh\n",
    "global_model = global_model.to(device)\n",
    "\n",
    "ema_decay = 0.99\n",
    "ema_global_model = copy.deepcopy(global_model)\n",
    "ema_global_model = ema_global_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9613dea-4edf-47cd-a042-5f3468b19d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "integer_to_label = {\n",
    "    0: 'HGSC',\n",
    "    1: 'CC',\n",
    "    2: 'EC',\n",
    "    3: 'LGSC',\n",
    "    4: 'MC',\n",
    "}\n",
    "\n",
    "label_to_integer = {\n",
    "    'HGSC': 0,\n",
    "    'CC': 1,\n",
    "    'EC': 2,\n",
    "    'LGSC': 3,\n",
    "    'MC': 4,\n",
    "}\n",
    "\n",
    "LOCAL_SAMPLES = 24\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        self.images_by_label_integer = {i: [] for i in range(5)}\n",
    "        \n",
    "        save_folder = '../image_tensors'\n",
    "\n",
    "        for index, row in dataframe.iterrows():\n",
    "            label = row['label']\n",
    "            image_id = row['image_id']\n",
    "            load_path = os.path.join(save_folder, f\"{image_id}.pt\")\n",
    "            images_tensor = torch.load(load_path, map_location=torch.device('cpu'))\n",
    "            self.images_by_label_integer[label_to_integer[label]].append(images_tensor)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1_000_000_000\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        n_labels = random.randint(1, 5)\n",
    "        labels = [0, 1, 2, 3, 4]\n",
    "        random.shuffle(labels)\n",
    "        labels = labels[:n_labels]\n",
    "\n",
    "        n_from_each_label = [0, 0, 0, 0, 0]\n",
    "        for _ in range(LOCAL_SAMPLES):\n",
    "            n_from_each_label[random.choice(labels)] += 1\n",
    "\n",
    "        images = []\n",
    "        for i in range(len(n_from_each_label)):\n",
    "            num_samples = n_from_each_label[i]\n",
    "            if num_samples == 0:\n",
    "                continue\n",
    "            selected_images_tensor_raw = self.images_by_label_integer[i][random.randint(0, len(self.images_by_label_integer[i]) - 1)]\n",
    "            selected_images_tensor = selected_images_tensor_raw[torch.randint(0, selected_images_tensor_raw.shape[0], (num_samples,))]\n",
    "            images.append(selected_images_tensor)\n",
    "        \n",
    "        images = torch.cat(images, dim=0)\n",
    "        label = torch.tensor(n_from_each_label) / LOCAL_SAMPLES\n",
    "        \n",
    "        return images, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daab3db2-8fff-4b14-83f9-608c256dea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "train_dataset = ImageDataset(dataframe=train)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aa0e2bd-4c21-48a1-a0fe-5eb15fb556b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Get the root logger\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Optional: Remove all existing handlers from the logger\n",
    "for handler in logger.handlers[:]:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "# Set the logging level\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create a FileHandler and add it to the logger\n",
    "file_handler = logging.FileHandler(f'logs/eva02_global_attention/seventh_try.txt')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Create a StreamHandler for stderr and add it to the logger\n",
    "stream_handler = logging.StreamHandler(sys.stderr)\n",
    "stream_handler.setLevel(logging.ERROR)  # Only log ERROR and CRITICAL messages to stderr\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f9b938-9860-4147-be7e-f6f36938f212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f41d0bc6b00>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import random\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "initial_lr = 0.0005 * BATCH_SIZE/256\n",
    "final_lr = initial_lr * 0.01\n",
    "num_epochs = 10000\n",
    "\n",
    "# Function for linear warmup\n",
    "def learning_rate(step, warmup_steps=100, max_steps=1000):\n",
    "    if step < warmup_steps:\n",
    "        return initial_lr * (float(step) / float(max(1, warmup_steps)))\n",
    "    elif step < max_steps:\n",
    "        progress = (float(step - warmup_steps) / float(max(1, max_steps - warmup_steps)))\n",
    "        cos_component = 0.5 * (1 + math.cos(math.pi * progress))\n",
    "        return final_lr + (initial_lr - final_lr) * cos_component\n",
    "    else:\n",
    "        return final_lr\n",
    "\n",
    "def update_ema_variables(model, ema_model, alpha):\n",
    "    # Update the EMA model parameters\n",
    "    with torch.no_grad():\n",
    "        for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
    "            ema_param.data.mul_(alpha).add_(param.data, alpha=1 - alpha)\n",
    "\n",
    "scaler = GradScaler()\n",
    "optimizer = optim.AdamW(global_model.parameters(), lr=initial_lr, weight_decay=5e-2)\n",
    "\n",
    "criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "best_val_accuracy = 0.0\n",
    "step = 0\n",
    "\n",
    "ema_global_model.eval()\n",
    "global_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for images, labels in train_dataloader:\n",
    "        # Convert images to PIL format\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Linearly increase the learning rate\n",
    "        lr = learning_rate(step)\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = lr\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass with autocast\n",
    "        with autocast():\n",
    "            global_outputs = global_model(images)\n",
    "            log_probs = F.log_softmax(global_outputs, dim=1)\n",
    "            loss = criterion(log_probs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        update_ema_variables(global_model, ema_global_model, ema_decay)\n",
    "\n",
    "        logging.info('[%d, %5d] loss: %.3f' % (epoch + 1, step, loss.item()))\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            torch.save(ema_global_model.state_dict(), f'eva02_global_attention_models/seventh_try/epoch_{epoch}_step_{step}.pth')\n",
    "            logging.info(f'Model saved after epoch {epoch} and step {step}')\\\n",
    "\n",
    "        if step == 1000:\n",
    "            torch.save(ema_global_model.state_dict(), f'eva02_global_attention_models/seventh_try/final.pth')\n",
    "\n",
    "        step += 1"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m114"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

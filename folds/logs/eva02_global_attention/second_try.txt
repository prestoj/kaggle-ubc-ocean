[1,     0] loss: 1.800
Model saved after epoch 0 and step 0
[2,     1] loss: 1.788
[3,     2] loss: 1.677
[4,     3] loss: 1.557
[5,     4] loss: 1.362
[6,     5] loss: 1.178
[7,     6] loss: 1.000
[8,     7] loss: 0.874
[9,     8] loss: 0.795
[10,     9] loss: 0.763
[11,    10] loss: 0.762
[12,    11] loss: 0.787
[13,    12] loss: 0.790
[14,    13] loss: 0.769
[15,    14] loss: 0.761
[16,    15] loss: 0.766
[17,    16] loss: 0.765
[18,    17] loss: 0.736
[19,    18] loss: 0.739
[20,    19] loss: 0.711
[21,    20] loss: 0.718
[22,    21] loss: 0.687
[23,    22] loss: 0.693
[24,    23] loss: 0.684
[25,    24] loss: 0.680
[26,    25] loss: 0.685
[27,    26] loss: 0.696
[28,    27] loss: 0.684
[29,    28] loss: 0.673
[30,    29] loss: 0.671
[31,    30] loss: 0.665
[32,    31] loss: 0.666
[33,    32] loss: 0.658
[34,    33] loss: 0.652
[35,    34] loss: 0.652
[36,    35] loss: 0.652
[37,    36] loss: 0.648
[38,    37] loss: 0.652
[39,    38] loss: 0.649
[40,    39] loss: 0.636
[41,    40] loss: 0.635
[42,    41] loss: 0.637
[43,    42] loss: 0.628
[44,    43] loss: 0.618
[45,    44] loss: 0.617
[46,    45] loss: 0.607
[47,    46] loss: 0.618
[48,    47] loss: 0.610
[49,    48] loss: 0.612
[50,    49] loss: 0.603
[51,    50] loss: 0.592
[52,    51] loss: 0.606
[53,    52] loss: 0.615
[54,    53] loss: 0.615
[55,    54] loss: 0.590
[56,    55] loss: 0.621
[57,    56] loss: 0.599
[58,    57] loss: 0.606
[59,    58] loss: 0.591
[60,    59] loss: 0.577
[61,    60] loss: 0.596
[62,    61] loss: 0.576
[63,    62] loss: 0.578
[64,    63] loss: 0.581
[65,    64] loss: 0.576
[66,    65] loss: 0.582
[67,    66] loss: 0.569
[68,    67] loss: 0.572
[69,    68] loss: 0.565
[70,    69] loss: 0.596
[71,    70] loss: 0.565
[72,    71] loss: 0.607
[73,    72] loss: 0.599
[74,    73] loss: 0.636
[75,    74] loss: 0.590
[76,    75] loss: 0.589
[77,    76] loss: 0.598
[78,    77] loss: 0.570
[79,    78] loss: 0.603
[80,    79] loss: 0.588
[81,    80] loss: 0.560
[82,    81] loss: 0.597
[83,    82] loss: 0.575
[84,    83] loss: 0.553
[85,    84] loss: 0.570
[86,    85] loss: 0.566
[87,    86] loss: 0.564
[88,    87] loss: 0.564
[89,    88] loss: 0.564
[90,    89] loss: 0.545
[91,    90] loss: 0.557
[92,    91] loss: 0.550
[93,    92] loss: 0.540
[94,    93] loss: 0.554
[95,    94] loss: 0.548
[96,    95] loss: 0.549
[97,    96] loss: 0.541
[98,    97] loss: 0.530
[99,    98] loss: 0.549
[100,    99] loss: 0.550
[101,   100] loss: 0.551
Model saved after epoch 100 and step 100
[102,   101] loss: 0.531
[103,   102] loss: 0.535
[104,   103] loss: 0.526
[105,   104] loss: 0.533
[106,   105] loss: 0.538
[107,   106] loss: 0.552
[108,   107] loss: 0.536
[109,   108] loss: 0.533
[110,   109] loss: 0.540
[111,   110] loss: 0.524
[112,   111] loss: 0.527
[113,   112] loss: 0.530
[114,   113] loss: 0.529
[115,   114] loss: 0.521
[116,   115] loss: 0.525
[117,   116] loss: 0.519
[118,   117] loss: 0.524
[119,   118] loss: 0.518
[120,   119] loss: 0.527
[121,   120] loss: 0.523
[122,   121] loss: 0.524
[123,   122] loss: 0.526
[124,   123] loss: 0.533
[125,   124] loss: 0.541
[126,   125] loss: 0.522
[127,   126] loss: 0.520
[128,   127] loss: 0.525
[129,   128] loss: 0.525
[130,   129] loss: 0.521
[131,   130] loss: 0.519
[132,   131] loss: 0.523
[133,   132] loss: 0.522
[134,   133] loss: 0.514
[135,   134] loss: 0.535
[136,   135] loss: 0.552
[137,   136] loss: 0.523
[138,   137] loss: 0.559
[139,   138] loss: 0.527
[140,   139] loss: 0.617
[141,   140] loss: 0.583
[142,   141] loss: 0.559
[143,   142] loss: 0.591
[144,   143] loss: 0.556
[145,   144] loss: 0.600
[146,   145] loss: 0.561
[147,   146] loss: 0.578
[148,   147] loss: 0.554
[149,   148] loss: 0.573
[150,   149] loss: 0.563
[151,   150] loss: 0.570
[152,   151] loss: 0.568
[153,   152] loss: 0.550
[154,   153] loss: 0.542
[155,   154] loss: 0.562
[156,   155] loss: 0.542
[157,   156] loss: 0.546
[158,   157] loss: 0.538
[159,   158] loss: 0.536
[160,   159] loss: 0.536
[161,   160] loss: 0.535
[162,   161] loss: 0.538
[163,   162] loss: 0.529
[164,   163] loss: 0.537
[165,   164] loss: 0.529
[166,   165] loss: 0.530
[167,   166] loss: 0.526
[168,   167] loss: 0.520
[169,   168] loss: 0.529
[170,   169] loss: 0.524
[171,   170] loss: 0.528
[172,   171] loss: 0.525
[173,   172] loss: 0.521
[174,   173] loss: 0.523
[175,   174] loss: 0.518
[176,   175] loss: 0.517
[177,   176] loss: 0.518
[178,   177] loss: 0.520
[179,   178] loss: 0.519
[180,   179] loss: 0.523
[181,   180] loss: 0.513
[182,   181] loss: 0.518
[183,   182] loss: 0.529
[184,   183] loss: 0.516
[185,   184] loss: 0.519
[186,   185] loss: 0.527
[187,   186] loss: 0.516
[188,   187] loss: 0.515
[189,   188] loss: 0.518
[190,   189] loss: 0.519
[191,   190] loss: 0.513
[192,   191] loss: 0.518
[193,   192] loss: 0.525
[194,   193] loss: 0.512
[195,   194] loss: 0.517
[196,   195] loss: 0.519
[197,   196] loss: 0.516
[198,   197] loss: 0.514
[199,   198] loss: 0.514
[200,   199] loss: 0.518
[201,   200] loss: 0.517
Model saved after epoch 200 and step 200
[202,   201] loss: 0.514
[203,   202] loss: 0.515
[204,   203] loss: 0.517
[205,   204] loss: 0.514
[206,   205] loss: 0.511
[207,   206] loss: 0.512
[208,   207] loss: 0.518
[209,   208] loss: 0.515
[210,   209] loss: 0.513
[211,   210] loss: 0.514
[212,   211] loss: 0.514
[213,   212] loss: 0.517
[214,   213] loss: 0.517
[215,   214] loss: 0.519
[216,   215] loss: 0.518
[217,   216] loss: 0.510
[218,   217] loss: 0.515
[219,   218] loss: 0.514
[220,   219] loss: 0.513
[221,   220] loss: 0.525
[222,   221] loss: 0.517
[223,   222] loss: 0.514
[224,   223] loss: 0.521
[225,   224] loss: 0.511
[226,   225] loss: 0.526
[227,   226] loss: 0.514
[228,   227] loss: 0.511
[229,   228] loss: 0.524
[230,   229] loss: 0.514
[231,   230] loss: 0.513
[232,   231] loss: 0.519
[233,   232] loss: 0.520
[234,   233] loss: 0.514
[235,   234] loss: 0.527
[236,   235] loss: 0.514
[237,   236] loss: 0.511
[238,   237] loss: 0.522
[239,   238] loss: 0.520
[240,   239] loss: 0.524
[241,   240] loss: 0.514
[242,   241] loss: 0.521
[243,   242] loss: 0.513
[244,   243] loss: 0.525
[245,   244] loss: 0.530
[246,   245] loss: 0.514
[247,   246] loss: 0.517
[248,   247] loss: 0.521
[249,   248] loss: 0.511
[250,   249] loss: 0.523
[251,   250] loss: 0.528
[252,   251] loss: 0.516
[253,   252] loss: 0.513
[254,   253] loss: 0.519
[255,   254] loss: 0.515
[256,   255] loss: 0.515
[257,   256] loss: 0.511
[258,   257] loss: 0.514
[259,   258] loss: 0.516
[260,   259] loss: 0.521
[261,   260] loss: 0.517
[262,   261] loss: 0.514
[263,   262] loss: 0.520
[264,   263] loss: 0.511
[265,   264] loss: 0.523
[266,   265] loss: 0.519
[267,   266] loss: 0.524
[268,   267] loss: 0.522
[269,   268] loss: 0.526
[270,   269] loss: 0.515
[271,   270] loss: 0.527
[272,   271] loss: 0.539
[273,   272] loss: 0.514
[274,   273] loss: 0.534
[275,   274] loss: 0.527
[276,   275] loss: 0.510
[277,   276] loss: 0.520
[278,   277] loss: 0.525
[279,   278] loss: 0.529
[280,   279] loss: 0.529
[281,   280] loss: 0.516
[282,   281] loss: 0.528
[283,   282] loss: 0.521
[284,   283] loss: 0.521
[285,   284] loss: 0.528
[286,   285] loss: 0.515
[287,   286] loss: 0.521
[288,   287] loss: 0.521
[289,   288] loss: 0.511
[290,   289] loss: 0.528
[291,   290] loss: 0.518
[292,   291] loss: 0.520
[293,   292] loss: 0.530
[294,   293] loss: 0.516
[295,   294] loss: 0.524
[296,   295] loss: 0.522
[297,   296] loss: 0.514
[298,   297] loss: 0.515
[299,   298] loss: 0.527
[300,   299] loss: 0.522
[301,   300] loss: 0.515
Model saved after epoch 300 and step 300
[302,   301] loss: 0.526
[303,   302] loss: 0.522
[304,   303] loss: 0.516
[305,   304] loss: 0.513
[306,   305] loss: 0.518
[307,   306] loss: 0.511
[308,   307] loss: 0.525
[309,   308] loss: 0.514
[310,   309] loss: 0.517
[311,   310] loss: 0.510
[312,   311] loss: 0.512
[313,   312] loss: 0.517
[314,   313] loss: 0.511
[315,   314] loss: 0.513
[316,   315] loss: 0.510
[317,   316] loss: 0.517
[318,   317] loss: 0.511
[319,   318] loss: 0.510
[320,   319] loss: 0.510
[321,   320] loss: 0.508
[322,   321] loss: 0.508
[323,   322] loss: 0.510
[324,   323] loss: 0.516
[325,   324] loss: 0.512
[326,   325] loss: 0.508
[327,   326] loss: 0.514
[328,   327] loss: 0.522
[329,   328] loss: 0.507
[330,   329] loss: 0.510
[331,   330] loss: 0.509
[332,   331] loss: 0.508
[333,   332] loss: 0.512
[334,   333] loss: 0.509
[335,   334] loss: 0.509
[336,   335] loss: 0.507
[337,   336] loss: 0.510
[338,   337] loss: 0.508
[339,   338] loss: 0.506
[340,   339] loss: 0.514
[341,   340] loss: 0.508
[342,   341] loss: 0.507
[343,   342] loss: 0.515
[344,   343] loss: 0.517
[345,   344] loss: 0.506
[346,   345] loss: 0.510
[347,   346] loss: 0.518
[348,   347] loss: 0.522
[349,   348] loss: 0.510
[350,   349] loss: 0.506
[351,   350] loss: 0.526
[352,   351] loss: 0.523
[353,   352] loss: 0.512
[354,   353] loss: 0.511
[355,   354] loss: 0.522
[356,   355] loss: 0.507
[357,   356] loss: 0.510
[358,   357] loss: 0.507
[359,   358] loss: 0.516
[360,   359] loss: 0.509
[361,   360] loss: 0.517
[362,   361] loss: 0.509
[363,   362] loss: 0.506
[364,   363] loss: 0.516
[365,   364] loss: 0.508
[366,   365] loss: 0.512
[367,   366] loss: 0.507
[368,   367] loss: 0.508
[369,   368] loss: 0.506
[370,   369] loss: 0.514
[371,   370] loss: 0.507
[372,   371] loss: 0.509
[373,   372] loss: 0.514
[374,   373] loss: 0.508
[375,   374] loss: 0.513
[376,   375] loss: 0.516
[377,   376] loss: 0.507
[378,   377] loss: 0.506
[379,   378] loss: 0.507
[380,   379] loss: 0.511
[381,   380] loss: 0.507
[382,   381] loss: 0.509
[383,   382] loss: 0.506
[384,   383] loss: 0.506
[385,   384] loss: 0.513
[386,   385] loss: 0.509
[387,   386] loss: 0.506
[388,   387] loss: 0.506
[389,   388] loss: 0.514
[390,   389] loss: 0.506
[391,   390] loss: 0.508
[392,   391] loss: 0.505
[393,   392] loss: 0.507
[394,   393] loss: 0.506
[395,   394] loss: 0.509
[396,   395] loss: 0.507
[397,   396] loss: 0.506
[398,   397] loss: 0.512
[399,   398] loss: 0.505
[400,   399] loss: 0.506
[401,   400] loss: 0.506
Model saved after epoch 400 and step 400
[402,   401] loss: 0.505
[403,   402] loss: 0.509
[404,   403] loss: 0.505
[405,   404] loss: 0.505
[406,   405] loss: 0.507
[407,   406] loss: 0.505
[408,   407] loss: 0.505
[409,   408] loss: 0.510
[410,   409] loss: 0.505
[411,   410] loss: 0.508
[412,   411] loss: 0.506
[413,   412] loss: 0.506
[414,   413] loss: 0.506
[415,   414] loss: 0.505
[416,   415] loss: 0.511
[417,   416] loss: 0.510
[418,   417] loss: 0.510
[419,   418] loss: 0.509
[420,   419] loss: 0.516
[421,   420] loss: 0.511
[422,   421] loss: 0.505
[423,   422] loss: 0.505
[424,   423] loss: 0.508
[425,   424] loss: 0.506
[426,   425] loss: 0.508
[427,   426] loss: 0.517
[428,   427] loss: 0.509
[429,   428] loss: 0.514
[430,   429] loss: 0.509
[431,   430] loss: 0.511
[432,   431] loss: 0.505
[433,   432] loss: 0.506
[434,   433] loss: 0.508
[435,   434] loss: 0.507
[436,   435] loss: 0.507
[437,   436] loss: 0.520
[438,   437] loss: 0.508
[439,   438] loss: 0.512
[440,   439] loss: 0.509
[441,   440] loss: 0.507
[442,   441] loss: 0.511
[443,   442] loss: 0.507
[444,   443] loss: 0.505
[445,   444] loss: 0.518
[446,   445] loss: 0.506
[447,   446] loss: 0.509
[448,   447] loss: 0.510
[449,   448] loss: 0.507
[450,   449] loss: 0.505
[451,   450] loss: 0.505
[452,   451] loss: 0.507
[453,   452] loss: 0.506
[454,   453] loss: 0.508
[455,   454] loss: 0.507
[456,   455] loss: 0.507
[457,   456] loss: 0.509
[458,   457] loss: 0.507
[459,   458] loss: 0.505
[460,   459] loss: 0.505
[461,   460] loss: 0.507
[462,   461] loss: 0.513
[463,   462] loss: 0.511
[464,   463] loss: 0.505
[465,   464] loss: 0.508
[466,   465] loss: 0.511
[467,   466] loss: 0.507
[468,   467] loss: 0.505
[469,   468] loss: 0.505
[470,   469] loss: 0.505
[471,   470] loss: 0.506
[472,   471] loss: 0.507
[473,   472] loss: 0.506
[474,   473] loss: 0.508
[475,   474] loss: 0.508
[476,   475] loss: 0.507
[477,   476] loss: 0.505
[478,   477] loss: 0.508
[479,   478] loss: 0.514
[480,   479] loss: 0.508
[481,   480] loss: 0.507
[482,   481] loss: 0.505
[483,   482] loss: 0.505
[484,   483] loss: 0.505
[485,   484] loss: 0.505
[486,   485] loss: 0.505
[487,   486] loss: 0.508
[488,   487] loss: 0.506
[489,   488] loss: 0.505
[490,   489] loss: 0.506
[491,   490] loss: 0.505
[492,   491] loss: 0.505
[493,   492] loss: 0.505
[494,   493] loss: 0.507
[495,   494] loss: 0.505
[496,   495] loss: 0.504
[497,   496] loss: 0.511
[498,   497] loss: 0.507
[499,   498] loss: 0.505
[500,   499] loss: 0.506
[501,   500] loss: 0.508
Model saved after epoch 500 and step 500
[502,   501] loss: 0.507
[503,   502] loss: 0.508
[504,   503] loss: 0.509
[505,   504] loss: 0.506
[506,   505] loss: 0.506
[507,   506] loss: 0.507
[508,   507] loss: 0.509
[509,   508] loss: 0.514
[510,   509] loss: 0.505
[511,   510] loss: 0.516
[512,   511] loss: 0.505
[513,   512] loss: 0.512
[514,   513] loss: 0.508
[515,   514] loss: 0.505
[516,   515] loss: 0.514
[517,   516] loss: 0.515
[518,   517] loss: 0.505
[519,   518] loss: 0.505
[520,   519] loss: 0.509
[521,   520] loss: 0.515
[522,   521] loss: 0.507
[523,   522] loss: 0.513
[524,   523] loss: 0.505
[525,   524] loss: 0.505
[526,   525] loss: 0.505
[527,   526] loss: 0.505
[528,   527] loss: 0.511
[529,   528] loss: 0.509
[530,   529] loss: 0.505
[531,   530] loss: 0.505
[532,   531] loss: 0.514
[533,   532] loss: 0.505
[534,   533] loss: 0.505
[535,   534] loss: 0.508
[536,   535] loss: 0.505
[537,   536] loss: 0.505
[538,   537] loss: 0.505
[539,   538] loss: 0.505
[540,   539] loss: 0.505
[541,   540] loss: 0.506
[542,   541] loss: 0.506
[543,   542] loss: 0.509
[544,   543] loss: 0.505
[545,   544] loss: 0.505
[546,   545] loss: 0.505
[547,   546] loss: 0.505
[548,   547] loss: 0.510
[549,   548] loss: 0.505
[550,   549] loss: 0.511
[551,   550] loss: 0.508
[552,   551] loss: 0.511
[553,   552] loss: 0.514
[554,   553] loss: 0.505
[555,   554] loss: 0.506
[556,   555] loss: 0.504
[557,   556] loss: 0.507
[558,   557] loss: 0.505
[559,   558] loss: 0.505
[560,   559] loss: 0.511
[561,   560] loss: 0.507
[562,   561] loss: 0.509
[563,   562] loss: 0.508
[564,   563] loss: 0.505
[565,   564] loss: 0.505
[566,   565] loss: 0.504
[567,   566] loss: 0.505
[568,   567] loss: 0.505
[569,   568] loss: 0.508
[570,   569] loss: 0.508
[571,   570] loss: 0.515
[572,   571] loss: 0.505
[573,   572] loss: 0.506
[574,   573] loss: 0.505
[575,   574] loss: 0.507
[576,   575] loss: 0.514
[577,   576] loss: 0.504
[578,   577] loss: 0.506
[579,   578] loss: 0.507
[580,   579] loss: 0.504
[581,   580] loss: 0.505
[582,   581] loss: 0.504
[583,   582] loss: 0.504
[584,   583] loss: 0.505
[585,   584] loss: 0.504
[586,   585] loss: 0.504
[587,   586] loss: 0.508
[588,   587] loss: 0.504
[589,   588] loss: 0.508
[590,   589] loss: 0.505
[591,   590] loss: 0.505
[592,   591] loss: 0.508
[593,   592] loss: 0.507
[594,   593] loss: 0.505
[595,   594] loss: 0.505
[596,   595] loss: 0.505
[597,   596] loss: 0.504
[598,   597] loss: 0.507
[599,   598] loss: 0.511
[600,   599] loss: 0.504
[601,   600] loss: 0.507
Model saved after epoch 600 and step 600
[602,   601] loss: 0.505
[603,   602] loss: 0.505
[604,   603] loss: 0.506
[605,   604] loss: 0.504
[606,   605] loss: 0.507
[607,   606] loss: 0.505
[608,   607] loss: 0.505
[609,   608] loss: 0.504
[610,   609] loss: 0.511
[611,   610] loss: 0.504
[612,   611] loss: 0.505
[613,   612] loss: 0.504
[614,   613] loss: 0.505
[615,   614] loss: 0.504
[616,   615] loss: 0.507
[617,   616] loss: 0.504
[618,   617] loss: 0.504
[619,   618] loss: 0.504
[620,   619] loss: 0.513
[621,   620] loss: 0.505
[622,   621] loss: 0.504
[623,   622] loss: 0.504
[624,   623] loss: 0.509
[625,   624] loss: 0.505
[626,   625] loss: 0.504
[627,   626] loss: 0.504
[628,   627] loss: 0.505
[629,   628] loss: 0.504
[630,   629] loss: 0.506
[631,   630] loss: 0.504
[632,   631] loss: 0.505
[633,   632] loss: 0.504
[634,   633] loss: 0.505
[635,   634] loss: 0.504
[636,   635] loss: 0.505
[637,   636] loss: 0.507
[638,   637] loss: 0.504
[639,   638] loss: 0.506
[640,   639] loss: 0.504
[641,   640] loss: 0.504
[642,   641] loss: 0.505
[643,   642] loss: 0.504
[644,   643] loss: 0.504
[645,   644] loss: 0.504
[646,   645] loss: 0.504
[647,   646] loss: 0.505
[648,   647] loss: 0.505
[649,   648] loss: 0.505
[650,   649] loss: 0.505
[651,   650] loss: 0.504
[652,   651] loss: 0.504
[653,   652] loss: 0.504
[654,   653] loss: 0.507
[655,   654] loss: 0.504
[656,   655] loss: 0.505
[657,   656] loss: 0.507
[658,   657] loss: 0.504
[659,   658] loss: 0.504
[660,   659] loss: 0.504
[661,   660] loss: 0.504
[662,   661] loss: 0.509
[663,   662] loss: 0.504
[664,   663] loss: 0.504
[665,   664] loss: 0.504
[666,   665] loss: 0.508
[667,   666] loss: 0.504
[668,   667] loss: 0.504
[669,   668] loss: 0.504
[670,   669] loss: 0.504
[671,   670] loss: 0.504
[672,   671] loss: 0.504
[673,   672] loss: 0.504
[674,   673] loss: 0.504
[675,   674] loss: 0.504
[676,   675] loss: 0.504
[677,   676] loss: 0.504
[678,   677] loss: 0.505
[679,   678] loss: 0.504
[680,   679] loss: 0.504
[681,   680] loss: 0.505
[682,   681] loss: 0.506
[683,   682] loss: 0.504
[684,   683] loss: 0.504
[685,   684] loss: 0.504
[686,   685] loss: 0.506
[687,   686] loss: 0.504
[688,   687] loss: 0.504
[689,   688] loss: 0.504
[690,   689] loss: 0.510
[691,   690] loss: 0.506
[692,   691] loss: 0.504
[693,   692] loss: 0.504
[694,   693] loss: 0.505
[695,   694] loss: 0.504
[696,   695] loss: 0.504
[697,   696] loss: 0.504
[698,   697] loss: 0.504
[699,   698] loss: 0.504
[700,   699] loss: 0.504
[701,   700] loss: 0.504
Model saved after epoch 700 and step 700
[702,   701] loss: 0.506
[703,   702] loss: 0.505
[704,   703] loss: 0.506
[705,   704] loss: 0.505
[706,   705] loss: 0.504
[707,   706] loss: 0.504
[708,   707] loss: 0.504
[709,   708] loss: 0.506
[710,   709] loss: 0.504
[711,   710] loss: 0.504
[712,   711] loss: 0.505
[713,   712] loss: 0.504
[714,   713] loss: 0.504
[715,   714] loss: 0.506
[716,   715] loss: 0.511
[717,   716] loss: 0.505
[718,   717] loss: 0.504
[719,   718] loss: 0.506
[720,   719] loss: 0.504
[721,   720] loss: 0.505
[722,   721] loss: 0.504
[723,   722] loss: 0.504
[724,   723] loss: 0.504
[725,   724] loss: 0.504
[726,   725] loss: 0.504
[727,   726] loss: 0.505
[728,   727] loss: 0.504
[729,   728] loss: 0.504
[730,   729] loss: 0.504
[731,   730] loss: 0.505
[732,   731] loss: 0.504
[733,   732] loss: 0.504
[734,   733] loss: 0.504
[735,   734] loss: 0.504
[736,   735] loss: 0.504
[737,   736] loss: 0.504
[738,   737] loss: 0.504
[739,   738] loss: 0.504
[740,   739] loss: 0.504
[741,   740] loss: 0.504
[742,   741] loss: 0.504
[743,   742] loss: 0.504
[744,   743] loss: 0.507
[745,   744] loss: 0.504
[746,   745] loss: 0.504
[747,   746] loss: 0.504
[748,   747] loss: 0.504
[749,   748] loss: 0.504
[750,   749] loss: 0.504
[751,   750] loss: 0.506
[752,   751] loss: 0.504
[753,   752] loss: 0.506
[754,   753] loss: 0.504
[755,   754] loss: 0.504
[756,   755] loss: 0.511
[757,   756] loss: 0.504
[758,   757] loss: 0.504
[759,   758] loss: 0.506
[760,   759] loss: 0.504
[761,   760] loss: 0.509
[762,   761] loss: 0.506
[763,   762] loss: 0.504
[764,   763] loss: 0.504
[765,   764] loss: 0.506
[766,   765] loss: 0.504
[767,   766] loss: 0.505
[768,   767] loss: 0.508
[769,   768] loss: 0.504
[770,   769] loss: 0.504
[771,   770] loss: 0.506
[772,   771] loss: 0.505
[773,   772] loss: 0.504
[774,   773] loss: 0.506
[775,   774] loss: 0.504
[776,   775] loss: 0.505
[777,   776] loss: 0.507
[778,   777] loss: 0.504
[779,   778] loss: 0.504
[780,   779] loss: 0.504
[781,   780] loss: 0.505
[782,   781] loss: 0.505
[783,   782] loss: 0.509
[784,   783] loss: 0.504
[785,   784] loss: 0.504
[786,   785] loss: 0.504
[787,   786] loss: 0.510
[788,   787] loss: 0.510
[789,   788] loss: 0.504
[790,   789] loss: 0.504
[791,   790] loss: 0.504
[792,   791] loss: 0.504
[793,   792] loss: 0.504
[794,   793] loss: 0.504
[795,   794] loss: 0.505
[796,   795] loss: 0.504
[797,   796] loss: 0.504
[798,   797] loss: 0.504
[799,   798] loss: 0.504
[800,   799] loss: 0.505
[801,   800] loss: 0.504
Model saved after epoch 800 and step 800
[802,   801] loss: 0.504
[803,   802] loss: 0.504
[804,   803] loss: 0.504
[805,   804] loss: 0.504
[806,   805] loss: 0.504
[807,   806] loss: 0.504
[808,   807] loss: 0.504
[809,   808] loss: 0.504
[810,   809] loss: 0.505
[811,   810] loss: 0.506
[812,   811] loss: 0.507
[813,   812] loss: 0.504
[814,   813] loss: 0.504
[815,   814] loss: 0.504
[816,   815] loss: 0.504
[817,   816] loss: 0.504
[818,   817] loss: 0.504
[819,   818] loss: 0.504
[820,   819] loss: 0.504
[821,   820] loss: 0.504
[822,   821] loss: 0.504
[823,   822] loss: 0.504
[824,   823] loss: 0.504
[825,   824] loss: 0.505
[826,   825] loss: 0.504
[827,   826] loss: 0.504
[828,   827] loss: 0.504
[829,   828] loss: 0.504
[830,   829] loss: 0.504
[831,   830] loss: 0.504
[832,   831] loss: 0.504
[833,   832] loss: 0.504
[834,   833] loss: 0.504
[835,   834] loss: 0.505
[836,   835] loss: 0.504
[837,   836] loss: 0.504
[838,   837] loss: 0.504
[839,   838] loss: 0.504
[840,   839] loss: 0.504
[841,   840] loss: 0.504
[842,   841] loss: 0.504
[843,   842] loss: 0.504
[844,   843] loss: 0.504
[845,   844] loss: 0.504
[846,   845] loss: 0.504
[847,   846] loss: 0.504
[848,   847] loss: 0.504
[849,   848] loss: 0.504
[850,   849] loss: 0.504
[851,   850] loss: 0.504
[852,   851] loss: 0.504
[853,   852] loss: 0.504
[854,   853] loss: 0.504
[855,   854] loss: 0.504
[856,   855] loss: 0.504
[857,   856] loss: 0.504
[858,   857] loss: 0.504
[859,   858] loss: 0.504
[860,   859] loss: 0.504
[861,   860] loss: 0.504
[862,   861] loss: 0.504
[863,   862] loss: 0.504
[864,   863] loss: 0.504
[865,   864] loss: 0.505
[866,   865] loss: 0.504
[867,   866] loss: 0.504
[868,   867] loss: 0.504
[869,   868] loss: 0.504
[870,   869] loss: 0.504
[871,   870] loss: 0.504
[872,   871] loss: 0.504
[873,   872] loss: 0.507
[874,   873] loss: 0.504
[875,   874] loss: 0.505
[876,   875] loss: 0.504
[877,   876] loss: 0.504
[878,   877] loss: 0.504
[879,   878] loss: 0.504
[880,   879] loss: 0.504
[881,   880] loss: 0.504
[882,   881] loss: 0.504
[883,   882] loss: 0.504
[884,   883] loss: 0.504
[885,   884] loss: 0.504
[886,   885] loss: 0.504
[887,   886] loss: 0.504
[888,   887] loss: 0.504
[889,   888] loss: 0.504
[890,   889] loss: 0.504
[891,   890] loss: 0.504
[892,   891] loss: 0.504
[893,   892] loss: 0.504
[894,   893] loss: 0.504
[895,   894] loss: 0.504
[896,   895] loss: 0.504
[897,   896] loss: 0.504
[898,   897] loss: 0.504
[899,   898] loss: 0.504
[900,   899] loss: 0.504
[901,   900] loss: 0.504
Model saved after epoch 900 and step 900
[902,   901] loss: 0.504
[903,   902] loss: 0.504
[904,   903] loss: 0.504
[905,   904] loss: 0.504
[906,   905] loss: 0.504
[907,   906] loss: 0.504
[908,   907] loss: 0.504
[909,   908] loss: 0.504
[910,   909] loss: 0.504
[911,   910] loss: 0.507
[912,   911] loss: 0.504
[913,   912] loss: 0.504
[914,   913] loss: 0.504
[915,   914] loss: 0.504
[916,   915] loss: 0.504
[917,   916] loss: 0.504
[918,   917] loss: 0.504
[919,   918] loss: 0.504
[920,   919] loss: 0.504
[921,   920] loss: 0.504
[922,   921] loss: 0.504
[923,   922] loss: 0.504
[924,   923] loss: 0.504
[925,   924] loss: 0.504
[926,   925] loss: 0.504
[927,   926] loss: 0.504
[928,   927] loss: 0.504
[929,   928] loss: 0.504
[930,   929] loss: 0.504
[931,   930] loss: 0.507
[932,   931] loss: 0.505
[933,   932] loss: 0.504
[934,   933] loss: 0.504
[935,   934] loss: 0.504
[936,   935] loss: 0.504
[937,   936] loss: 0.504
[938,   937] loss: 0.504
[939,   938] loss: 0.504
[940,   939] loss: 0.505
[941,   940] loss: 0.504
[942,   941] loss: 0.504
[943,   942] loss: 0.504
[944,   943] loss: 0.504
[945,   944] loss: 0.504
[946,   945] loss: 0.504
[947,   946] loss: 0.507
[948,   947] loss: 0.504
[949,   948] loss: 0.504
[950,   949] loss: 0.504
[951,   950] loss: 0.504
[952,   951] loss: 0.504
[953,   952] loss: 0.504
[954,   953] loss: 0.504
[955,   954] loss: 0.504
[956,   955] loss: 0.504
[957,   956] loss: 0.504
[958,   957] loss: 0.504
[959,   958] loss: 0.504
[960,   959] loss: 0.504
[961,   960] loss: 0.504
[962,   961] loss: 0.505
[963,   962] loss: 0.504
[964,   963] loss: 0.504
[965,   964] loss: 0.504
[966,   965] loss: 0.505
[967,   966] loss: 0.504
[968,   967] loss: 0.504
[969,   968] loss: 0.504
[970,   969] loss: 0.504
[971,   970] loss: 0.504
[972,   971] loss: 0.504
[973,   972] loss: 0.504
[974,   973] loss: 0.504
[975,   974] loss: 0.504
[976,   975] loss: 0.504
[977,   976] loss: 0.504
[978,   977] loss: 0.504
[979,   978] loss: 0.504
[980,   979] loss: 0.504
[981,   980] loss: 0.504
[982,   981] loss: 0.504
[983,   982] loss: 0.504
[984,   983] loss: 0.504
[985,   984] loss: 0.504
[986,   985] loss: 0.504
[987,   986] loss: 0.505
[988,   987] loss: 0.504
[989,   988] loss: 0.504
[990,   989] loss: 0.504
[991,   990] loss: 0.504
[992,   991] loss: 0.504
[993,   992] loss: 0.504
[994,   993] loss: 0.504
[995,   994] loss: 0.504
[996,   995] loss: 0.504
[997,   996] loss: 0.504
[998,   997] loss: 0.504
[999,   998] loss: 0.506
[1000,   999] loss: 0.504
[1001,  1000] loss: 0.504
Model saved after epoch 1000 and step 1000
[1002,  1001] loss: 0.504
[1003,  1002] loss: 0.504
[1004,  1003] loss: 0.504
[1005,  1004] loss: 0.504
[1006,  1005] loss: 0.504
[1007,  1006] loss: 0.504
[1008,  1007] loss: 0.504
[1009,  1008] loss: 0.504
[1010,  1009] loss: 0.504
[1011,  1010] loss: 0.504
[1012,  1011] loss: 0.504
[1013,  1012] loss: 0.504
[1014,  1013] loss: 0.504
[1015,  1014] loss: 0.504
[1016,  1015] loss: 0.504

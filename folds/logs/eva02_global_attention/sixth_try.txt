[1,     0] loss: 0.678
Model saved after epoch 0 and step 0
[1,     1] loss: 0.675
[1,     2] loss: 0.654
[1,     3] loss: 0.612
[1,     4] loss: 0.597
[1,     5] loss: 0.583
[1,     6] loss: 0.557
[1,     7] loss: 0.499
[1,     8] loss: 0.474
[1,     9] loss: 0.444
[1,    10] loss: 0.424
[1,    11] loss: 0.372
[1,    12] loss: 0.378
[1,    13] loss: 0.341
[1,    14] loss: 0.349
[1,    15] loss: 0.328
[1,    16] loss: 0.323
[1,    17] loss: 0.319
[1,    18] loss: 0.342
[1,    19] loss: 0.333
[1,    20] loss: 0.316
[1,    21] loss: 0.322
[1,    22] loss: 0.345
[1,    23] loss: 0.318
[1,    24] loss: 0.307
[1,    25] loss: 0.295
[1,    26] loss: 0.289
[1,    27] loss: 0.280
[1,    28] loss: 0.293
[1,    29] loss: 0.263
[1,    30] loss: 0.286
[1,    31] loss: 0.274
[1,    32] loss: 0.296
[1,    33] loss: 0.279
[1,    34] loss: 0.303
[1,    35] loss: 0.277
[1,    36] loss: 0.255
[1,    37] loss: 0.301
[1,    38] loss: 0.278
[1,    39] loss: 0.261
[1,    40] loss: 0.258
[1,    41] loss: 0.253
[1,    42] loss: 0.254
[1,    43] loss: 0.260
[1,    44] loss: 0.257
[1,    45] loss: 0.249
[1,    46] loss: 0.265
[1,    47] loss: 0.259
[1,    48] loss: 0.254
[1,    49] loss: 0.256
[1,    50] loss: 0.261
[1,    51] loss: 0.239
[1,    52] loss: 0.266
[1,    53] loss: 0.257
[1,    54] loss: 0.231
[1,    55] loss: 0.243
[1,    56] loss: 0.240
[1,    57] loss: 0.246
[1,    58] loss: 0.253
[1,    59] loss: 0.250
[1,    60] loss: 0.230
[1,    61] loss: 0.226
[1,    62] loss: 0.250
[1,    63] loss: 0.252
[1,    64] loss: 0.248
[1,    65] loss: 0.226
[1,    66] loss: 0.235
[1,    67] loss: 0.224
[1,    68] loss: 0.222
[1,    69] loss: 0.202
[1,    70] loss: 0.215
[1,    71] loss: 0.209
[1,    72] loss: 0.205
[1,    73] loss: 0.208
[1,    74] loss: 0.219
[1,    75] loss: 0.216
[1,    76] loss: 0.213
[1,    77] loss: 0.207
[1,    78] loss: 0.221
[1,    79] loss: 0.193
[1,    80] loss: 0.215
[1,    81] loss: 0.211
[1,    82] loss: 0.190
[1,    83] loss: 0.226
[1,    84] loss: 0.214
[1,    85] loss: 0.197
[1,    86] loss: 0.191
[1,    87] loss: 0.188
[1,    88] loss: 0.196
[1,    89] loss: 0.201
[1,    90] loss: 0.195
[1,    91] loss: 0.158
[1,    92] loss: 0.187
[1,    93] loss: 0.188
[1,    94] loss: 0.188
[1,    95] loss: 0.179
[1,    96] loss: 0.190
[1,    97] loss: 0.182
[1,    98] loss: 0.186
[1,    99] loss: 0.188
[1,   100] loss: 0.192
Model saved after epoch 0 and step 100
[1,   101] loss: 0.204
[1,   102] loss: 0.181
[1,   103] loss: 0.177
[1,   104] loss: 0.182
[1,   105] loss: 0.181
[1,   106] loss: 0.197
[1,   107] loss: 0.162
[1,   108] loss: 0.186
[1,   109] loss: 0.187
[1,   110] loss: 0.200
[1,   111] loss: 0.171
[1,   112] loss: 0.173
[1,   113] loss: 0.174
[1,   114] loss: 0.177
[1,   115] loss: 0.198
[1,   116] loss: 0.176
[1,   117] loss: 0.189
[1,   118] loss: 0.194
[1,   119] loss: 0.163
[1,   120] loss: 0.190
[1,   121] loss: 0.171
[1,   122] loss: 0.170
[1,   123] loss: 0.166
[1,   124] loss: 0.171
[1,   125] loss: 0.166
[1,   126] loss: 0.164
[1,   127] loss: 0.164
[1,   128] loss: 0.161
[1,   129] loss: 0.153
[1,   130] loss: 0.162
[1,   131] loss: 0.159
[1,   132] loss: 0.166
[1,   133] loss: 0.158
[1,   134] loss: 0.149
[1,   135] loss: 0.145
[1,   136] loss: 0.161
[1,   137] loss: 0.149
[1,   138] loss: 0.173
[1,   139] loss: 0.146
[1,   140] loss: 0.163
[1,   141] loss: 0.145
[1,   142] loss: 0.157
[1,   143] loss: 0.170
[1,   144] loss: 0.147
[1,   145] loss: 0.157
[1,   146] loss: 0.155
[1,   147] loss: 0.167
[1,   148] loss: 0.172
[1,   149] loss: 0.160
[1,   150] loss: 0.147
[1,   151] loss: 0.160
[1,   152] loss: 0.148
[1,   153] loss: 0.164
[1,   154] loss: 0.164
[1,   155] loss: 0.146
[1,   156] loss: 0.162
[1,   157] loss: 0.146
[1,   158] loss: 0.155
[1,   159] loss: 0.150
[1,   160] loss: 0.154
[1,   161] loss: 0.145
[1,   162] loss: 0.169
[1,   163] loss: 0.149
[1,   164] loss: 0.153
[1,   165] loss: 0.151
[1,   166] loss: 0.159
[1,   167] loss: 0.143
[1,   168] loss: 0.150
[1,   169] loss: 0.166
[1,   170] loss: 0.138
[1,   171] loss: 0.141
[1,   172] loss: 0.148
[1,   173] loss: 0.130
[1,   174] loss: 0.148
[1,   175] loss: 0.136
[1,   176] loss: 0.137
[1,   177] loss: 0.140
[1,   178] loss: 0.143
[1,   179] loss: 0.160
[1,   180] loss: 0.133
[1,   181] loss: 0.126
[1,   182] loss: 0.134
[1,   183] loss: 0.138
[1,   184] loss: 0.137
[1,   185] loss: 0.135
[1,   186] loss: 0.124
[1,   187] loss: 0.141
[1,   188] loss: 0.123
[1,   189] loss: 0.152
[1,   190] loss: 0.137
[1,   191] loss: 0.147
[1,   192] loss: 0.131
[1,   193] loss: 0.136
[1,   194] loss: 0.128
[1,   195] loss: 0.138
[1,   196] loss: 0.148
[1,   197] loss: 0.129
[1,   198] loss: 0.151
[1,   199] loss: 0.131
[1,   200] loss: 0.137
Model saved after epoch 0 and step 200
[1,   201] loss: 0.149
[1,   202] loss: 0.131
[1,   203] loss: 0.148
[1,   204] loss: 0.131
[1,   205] loss: 0.151
[1,   206] loss: 0.131
[1,   207] loss: 0.134
[1,   208] loss: 0.125
[1,   209] loss: 0.141
[1,   210] loss: 0.129
[1,   211] loss: 0.129
[1,   212] loss: 0.134
[1,   213] loss: 0.130
[1,   214] loss: 0.125
[1,   215] loss: 0.139
[1,   216] loss: 0.126
[1,   217] loss: 0.121
[1,   218] loss: 0.130
[1,   219] loss: 0.125
[1,   220] loss: 0.124
[1,   221] loss: 0.116
[1,   222] loss: 0.126
[1,   223] loss: 0.120
[1,   224] loss: 0.128
[1,   225] loss: 0.124
[1,   226] loss: 0.129
[1,   227] loss: 0.134
[1,   228] loss: 0.113
[1,   229] loss: 0.132
[1,   230] loss: 0.113
[1,   231] loss: 0.147
[1,   232] loss: 0.114
[1,   233] loss: 0.124
[1,   234] loss: 0.122
[1,   235] loss: 0.127
[1,   236] loss: 0.123
[1,   237] loss: 0.118
[1,   238] loss: 0.124
[1,   239] loss: 0.116
[1,   240] loss: 0.119
[1,   241] loss: 0.121
[1,   242] loss: 0.115
[1,   243] loss: 0.122
[1,   244] loss: 0.113
[1,   245] loss: 0.126
[1,   246] loss: 0.121
[1,   247] loss: 0.117
[1,   248] loss: 0.114
[1,   249] loss: 0.114
[1,   250] loss: 0.110
[1,   251] loss: 0.132
[1,   252] loss: 0.118
[1,   253] loss: 0.123
[1,   254] loss: 0.120
[1,   255] loss: 0.126
[1,   256] loss: 0.117
[1,   257] loss: 0.118
[1,   258] loss: 0.112
[1,   259] loss: 0.107
[1,   260] loss: 0.107
[1,   261] loss: 0.108
[1,   262] loss: 0.095
[1,   263] loss: 0.123
[1,   264] loss: 0.118
[1,   265] loss: 0.114
[1,   266] loss: 0.103
[1,   267] loss: 0.115
[1,   268] loss: 0.110
[1,   269] loss: 0.123
[1,   270] loss: 0.107
[1,   271] loss: 0.123
[1,   272] loss: 0.106
[1,   273] loss: 0.114
[1,   274] loss: 0.121
[1,   275] loss: 0.115
[1,   276] loss: 0.111
[1,   277] loss: 0.140
[1,   278] loss: 0.115
[1,   279] loss: 0.106
[1,   280] loss: 0.113
[1,   281] loss: 0.122
[1,   282] loss: 0.121
[1,   283] loss: 0.108
[1,   284] loss: 0.115
[1,   285] loss: 0.113
[1,   286] loss: 0.115
[1,   287] loss: 0.110
[1,   288] loss: 0.112
[1,   289] loss: 0.107
[1,   290] loss: 0.114
[1,   291] loss: 0.106
[1,   292] loss: 0.105
[1,   293] loss: 0.102
[1,   294] loss: 0.099
[1,   295] loss: 0.106
[1,   296] loss: 0.102
[1,   297] loss: 0.112
[1,   298] loss: 0.102
[1,   299] loss: 0.102
[1,   300] loss: 0.116
Model saved after epoch 0 and step 300
[1,   301] loss: 0.116
[1,   302] loss: 0.115
[1,   303] loss: 0.111
[1,   304] loss: 0.103
[1,   305] loss: 0.101
[1,   306] loss: 0.113
[1,   307] loss: 0.118
[1,   308] loss: 0.097
[1,   309] loss: 0.113
[1,   310] loss: 0.116
[1,   311] loss: 0.116
[1,   312] loss: 0.102
[1,   313] loss: 0.105
[1,   314] loss: 0.106
[1,   315] loss: 0.105
[1,   316] loss: 0.108
[1,   317] loss: 0.102
[1,   318] loss: 0.098
[1,   319] loss: 0.107
[1,   320] loss: 0.100
[1,   321] loss: 0.099
[1,   322] loss: 0.108
[1,   323] loss: 0.105
[1,   324] loss: 0.104
[1,   325] loss: 0.117
[1,   326] loss: 0.103
[1,   327] loss: 0.106
[1,   328] loss: 0.097
[1,   329] loss: 0.101
[1,   330] loss: 0.109
[1,   331] loss: 0.102
[1,   332] loss: 0.107
[1,   333] loss: 0.112
[1,   334] loss: 0.107
[1,   335] loss: 0.098
[1,   336] loss: 0.097
[1,   337] loss: 0.090
[1,   338] loss: 0.117
[1,   339] loss: 0.100
[1,   340] loss: 0.098
[1,   341] loss: 0.096
[1,   342] loss: 0.096
[1,   343] loss: 0.104
[1,   344] loss: 0.104
[1,   345] loss: 0.101
[1,   346] loss: 0.100
[1,   347] loss: 0.090
[1,   348] loss: 0.098
[1,   349] loss: 0.103
[1,   350] loss: 0.109
[1,   351] loss: 0.101
[1,   352] loss: 0.091
[1,   353] loss: 0.098
[1,   354] loss: 0.096
[1,   355] loss: 0.096
[1,   356] loss: 0.107
[1,   357] loss: 0.095
[1,   358] loss: 0.104
[1,   359] loss: 0.094
[1,   360] loss: 0.100
[1,   361] loss: 0.097
[1,   362] loss: 0.098
[1,   363] loss: 0.096
[1,   364] loss: 0.092
[1,   365] loss: 0.091
[1,   366] loss: 0.095
[1,   367] loss: 0.099
[1,   368] loss: 0.090
[1,   369] loss: 0.097
[1,   370] loss: 0.088
[1,   371] loss: 0.092
[1,   372] loss: 0.095
[1,   373] loss: 0.085
[1,   374] loss: 0.097
[1,   375] loss: 0.088
[1,   376] loss: 0.095
[1,   377] loss: 0.094
[1,   378] loss: 0.088
[1,   379] loss: 0.084
[1,   380] loss: 0.085
[1,   381] loss: 0.095
[1,   382] loss: 0.097
[1,   383] loss: 0.098
[1,   384] loss: 0.097
[1,   385] loss: 0.100
[1,   386] loss: 0.087
[1,   387] loss: 0.112
[1,   388] loss: 0.100
[1,   389] loss: 0.111
[1,   390] loss: 0.094
[1,   391] loss: 0.108
[1,   392] loss: 0.102
[1,   393] loss: 0.105
[1,   394] loss: 0.099
[1,   395] loss: 0.102
[1,   396] loss: 0.103
[1,   397] loss: 0.091
[1,   398] loss: 0.100
[1,   399] loss: 0.091
[1,   400] loss: 0.087
Model saved after epoch 0 and step 400
[1,   401] loss: 0.096
[1,   402] loss: 0.091
[1,   403] loss: 0.106
[1,   404] loss: 0.097
[1,   405] loss: 0.081
[1,   406] loss: 0.098
[1,   407] loss: 0.084
[1,   408] loss: 0.085
[1,   409] loss: 0.100
[1,   410] loss: 0.090
[1,   411] loss: 0.095
[1,   412] loss: 0.087
[1,   413] loss: 0.093
[1,   414] loss: 0.099
[1,   415] loss: 0.087
[1,   416] loss: 0.084
[1,   417] loss: 0.091
[1,   418] loss: 0.086
[1,   419] loss: 0.086
[1,   420] loss: 0.101
[1,   421] loss: 0.087
[1,   422] loss: 0.086
[1,   423] loss: 0.083
[1,   424] loss: 0.094
[1,   425] loss: 0.088
[1,   426] loss: 0.092
[1,   427] loss: 0.081
[1,   428] loss: 0.090
[1,   429] loss: 0.088
[1,   430] loss: 0.091
[1,   431] loss: 0.085
[1,   432] loss: 0.088
[1,   433] loss: 0.085
[1,   434] loss: 0.090
[1,   435] loss: 0.079
[1,   436] loss: 0.088
[1,   437] loss: 0.082
[1,   438] loss: 0.092
[1,   439] loss: 0.093
[1,   440] loss: 0.086
[1,   441] loss: 0.087
[1,   442] loss: 0.081
[1,   443] loss: 0.086
[1,   444] loss: 0.087
[1,   445] loss: 0.080
[1,   446] loss: 0.084
[1,   447] loss: 0.093
[1,   448] loss: 0.085
[1,   449] loss: 0.081
[1,   450] loss: 0.083
[1,   451] loss: 0.074
[1,   452] loss: 0.094
[1,   453] loss: 0.095
[1,   454] loss: 0.076
[1,   455] loss: 0.089
[1,   456] loss: 0.071
[1,   457] loss: 0.088
[1,   458] loss: 0.084
[1,   459] loss: 0.082
[1,   460] loss: 0.086
[1,   461] loss: 0.092
[1,   462] loss: 0.084
[1,   463] loss: 0.089
[1,   464] loss: 0.088
[1,   465] loss: 0.088
[1,   466] loss: 0.085
[1,   467] loss: 0.093
[1,   468] loss: 0.089
[1,   469] loss: 0.085
[1,   470] loss: 0.086
[1,   471] loss: 0.081
[1,   472] loss: 0.075
[1,   473] loss: 0.080
[1,   474] loss: 0.088
[1,   475] loss: 0.084
[1,   476] loss: 0.081
[1,   477] loss: 0.077
[1,   478] loss: 0.074
[1,   479] loss: 0.091
[1,   480] loss: 0.081
[1,   481] loss: 0.087
[1,   482] loss: 0.081
[1,   483] loss: 0.089
[1,   484] loss: 0.086
[1,   485] loss: 0.085
[1,   486] loss: 0.088
[1,   487] loss: 0.085
[1,   488] loss: 0.108
[1,   489] loss: 0.083
[1,   490] loss: 0.092
[1,   491] loss: 0.081
[1,   492] loss: 0.076
[1,   493] loss: 0.078
[1,   494] loss: 0.085
[1,   495] loss: 0.077
[1,   496] loss: 0.082
[1,   497] loss: 0.088
[1,   498] loss: 0.085
[1,   499] loss: 0.073
[1,   500] loss: 0.082
Model saved after epoch 0 and step 500
[1,   501] loss: 0.078
[1,   502] loss: 0.074
[1,   503] loss: 0.079
[1,   504] loss: 0.071
[1,   505] loss: 0.083
[1,   506] loss: 0.080
[1,   507] loss: 0.078
[1,   508] loss: 0.078
[1,   509] loss: 0.083
[1,   510] loss: 0.078
[1,   511] loss: 0.073
[1,   512] loss: 0.076
[1,   513] loss: 0.083
[1,   514] loss: 0.078
[1,   515] loss: 0.080
[1,   516] loss: 0.078
[1,   517] loss: 0.074
[1,   518] loss: 0.077
[1,   519] loss: 0.072
[1,   520] loss: 0.085
[1,   521] loss: 0.077
[1,   522] loss: 0.078
[1,   523] loss: 0.074
[1,   524] loss: 0.078
[1,   525] loss: 0.082
[1,   526] loss: 0.077
[1,   527] loss: 0.080
[1,   528] loss: 0.081
[1,   529] loss: 0.079
[1,   530] loss: 0.084
[1,   531] loss: 0.081
[1,   532] loss: 0.091
[1,   533] loss: 0.079
[1,   534] loss: 0.074
[1,   535] loss: 0.067
[1,   536] loss: 0.079
[1,   537] loss: 0.085
[1,   538] loss: 0.080
[1,   539] loss: 0.073
[1,   540] loss: 0.077
[1,   541] loss: 0.080
[1,   542] loss: 0.080
[1,   543] loss: 0.075
[1,   544] loss: 0.076
[1,   545] loss: 0.077
[1,   546] loss: 0.078
[1,   547] loss: 0.083
[1,   548] loss: 0.074
[1,   549] loss: 0.079
[1,   550] loss: 0.072
[1,   551] loss: 0.075
[1,   552] loss: 0.082
[1,   553] loss: 0.075
[1,   554] loss: 0.081
[1,   555] loss: 0.063
[1,   556] loss: 0.066
[1,   557] loss: 0.077
[1,   558] loss: 0.076
[1,   559] loss: 0.080
[1,   560] loss: 0.079
[1,   561] loss: 0.088
[1,   562] loss: 0.081
[1,   563] loss: 0.079
[1,   564] loss: 0.094
[1,   565] loss: 0.074
[1,   566] loss: 0.077
[1,   567] loss: 0.079
[1,   568] loss: 0.076
[1,   569] loss: 0.072
[1,   570] loss: 0.067
[1,   571] loss: 0.080
[1,   572] loss: 0.077
[1,   573] loss: 0.078
[1,   574] loss: 0.077
[1,   575] loss: 0.081
[1,   576] loss: 0.084
[1,   577] loss: 0.085
[1,   578] loss: 0.077
[1,   579] loss: 0.071
[1,   580] loss: 0.079
[1,   581] loss: 0.075
[1,   582] loss: 0.075
[1,   583] loss: 0.080
[1,   584] loss: 0.063
[1,   585] loss: 0.066
[1,   586] loss: 0.076
[1,   587] loss: 0.063
[1,   588] loss: 0.077
[1,   589] loss: 0.083
[1,   590] loss: 0.073
[1,   591] loss: 0.063
[1,   592] loss: 0.072
[1,   593] loss: 0.069
[1,   594] loss: 0.074
[1,   595] loss: 0.067
[1,   596] loss: 0.072
[1,   597] loss: 0.072
[1,   598] loss: 0.063
[1,   599] loss: 0.078
[1,   600] loss: 0.075
Model saved after epoch 0 and step 600
[1,   601] loss: 0.072
[1,   602] loss: 0.076
[1,   603] loss: 0.076
[1,   604] loss: 0.076
[1,   605] loss: 0.079
[1,   606] loss: 0.075
[1,   607] loss: 0.073
[1,   608] loss: 0.071
[1,   609] loss: 0.077
[1,   610] loss: 0.073
[1,   611] loss: 0.078
[1,   612] loss: 0.065
[1,   613] loss: 0.072
[1,   614] loss: 0.071
[1,   615] loss: 0.067
[1,   616] loss: 0.071
[1,   617] loss: 0.069
[1,   618] loss: 0.065
[1,   619] loss: 0.074
[1,   620] loss: 0.064
[1,   621] loss: 0.064
[1,   622] loss: 0.074
[1,   623] loss: 0.066
[1,   624] loss: 0.073
[1,   625] loss: 0.069
[1,   626] loss: 0.066
[1,   627] loss: 0.070
[1,   628] loss: 0.069
[1,   629] loss: 0.072
[1,   630] loss: 0.071
[1,   631] loss: 0.068
[1,   632] loss: 0.073
[1,   633] loss: 0.065
[1,   634] loss: 0.073
[1,   635] loss: 0.070
[1,   636] loss: 0.074
[1,   637] loss: 0.063
[1,   638] loss: 0.070
[1,   639] loss: 0.072
[1,   640] loss: 0.080
[1,   641] loss: 0.072
[1,   642] loss: 0.068
[1,   643] loss: 0.067
[1,   644] loss: 0.062
[1,   645] loss: 0.067
[1,   646] loss: 0.068
[1,   647] loss: 0.062
[1,   648] loss: 0.069
[1,   649] loss: 0.078
[1,   650] loss: 0.061
[1,   651] loss: 0.070
[1,   652] loss: 0.072
[1,   653] loss: 0.058
[1,   654] loss: 0.063
[1,   655] loss: 0.065
[1,   656] loss: 0.071
[1,   657] loss: 0.074
[1,   658] loss: 0.067
[1,   659] loss: 0.068
[1,   660] loss: 0.069
[1,   661] loss: 0.073
[1,   662] loss: 0.066
[1,   663] loss: 0.072
[1,   664] loss: 0.065
[1,   665] loss: 0.065
[1,   666] loss: 0.068
[1,   667] loss: 0.063
[1,   668] loss: 0.069
[1,   669] loss: 0.066
[1,   670] loss: 0.062
[1,   671] loss: 0.066
[1,   672] loss: 0.068
[1,   673] loss: 0.075
[1,   674] loss: 0.061
[1,   675] loss: 0.072
[1,   676] loss: 0.071
[1,   677] loss: 0.068
[1,   678] loss: 0.064
[1,   679] loss: 0.064
[1,   680] loss: 0.067
[1,   681] loss: 0.072
[1,   682] loss: 0.071
[1,   683] loss: 0.064
[1,   684] loss: 0.060
[1,   685] loss: 0.072
[1,   686] loss: 0.074
[1,   687] loss: 0.063
[1,   688] loss: 0.060
[1,   689] loss: 0.071
[1,   690] loss: 0.071
[1,   691] loss: 0.068
[1,   692] loss: 0.075
[1,   693] loss: 0.060
[1,   694] loss: 0.066
[1,   695] loss: 0.069
[1,   696] loss: 0.067
[1,   697] loss: 0.071
[1,   698] loss: 0.067
[1,   699] loss: 0.064
[1,   700] loss: 0.070
Model saved after epoch 0 and step 700
[1,   701] loss: 0.065
[1,   702] loss: 0.066
[1,   703] loss: 0.065
[1,   704] loss: 0.075
[1,   705] loss: 0.073
[1,   706] loss: 0.066
[1,   707] loss: 0.070
[1,   708] loss: 0.067
[1,   709] loss: 0.062
[1,   710] loss: 0.068
[1,   711] loss: 0.068
[1,   712] loss: 0.064
[1,   713] loss: 0.065
[1,   714] loss: 0.072
[1,   715] loss: 0.066
[1,   716] loss: 0.069
[1,   717] loss: 0.061
[1,   718] loss: 0.069
[1,   719] loss: 0.064
[1,   720] loss: 0.064
[1,   721] loss: 0.067
[1,   722] loss: 0.063
[1,   723] loss: 0.062
[1,   724] loss: 0.064
[1,   725] loss: 0.065
[1,   726] loss: 0.062
[1,   727] loss: 0.059
[1,   728] loss: 0.063
[1,   729] loss: 0.065
[1,   730] loss: 0.065
[1,   731] loss: 0.070
[1,   732] loss: 0.057
[1,   733] loss: 0.060
[1,   734] loss: 0.072
[1,   735] loss: 0.066
[1,   736] loss: 0.065
[1,   737] loss: 0.063
[1,   738] loss: 0.064
[1,   739] loss: 0.070
[1,   740] loss: 0.064
[1,   741] loss: 0.062
[1,   742] loss: 0.066
[1,   743] loss: 0.067
[1,   744] loss: 0.062
[1,   745] loss: 0.059
[1,   746] loss: 0.066
[1,   747] loss: 0.064
[1,   748] loss: 0.060
[1,   749] loss: 0.069
[1,   750] loss: 0.069
[1,   751] loss: 0.063
[1,   752] loss: 0.068
[1,   753] loss: 0.070
[1,   754] loss: 0.061
[1,   755] loss: 0.060
[1,   756] loss: 0.064
[1,   757] loss: 0.062
[1,   758] loss: 0.068
[1,   759] loss: 0.061
[1,   760] loss: 0.067
[1,   761] loss: 0.065
[1,   762] loss: 0.068
[1,   763] loss: 0.061
[1,   764] loss: 0.062
[1,   765] loss: 0.071
[1,   766] loss: 0.064
[1,   767] loss: 0.069
[1,   768] loss: 0.069
[1,   769] loss: 0.065
[1,   770] loss: 0.068
[1,   771] loss: 0.066
[1,   772] loss: 0.069
[1,   773] loss: 0.065
[1,   774] loss: 0.059
[1,   775] loss: 0.062
[1,   776] loss: 0.066
[1,   777] loss: 0.062
[1,   778] loss: 0.064
[1,   779] loss: 0.062
[1,   780] loss: 0.065
[1,   781] loss: 0.064
[1,   782] loss: 0.058
[1,   783] loss: 0.057
[1,   784] loss: 0.061
[1,   785] loss: 0.065
[1,   786] loss: 0.059
[1,   787] loss: 0.063
[1,   788] loss: 0.063
[1,   789] loss: 0.063
[1,   790] loss: 0.057
[1,   791] loss: 0.060
[1,   792] loss: 0.067
[1,   793] loss: 0.059
[1,   794] loss: 0.071
[1,   795] loss: 0.064
[1,   796] loss: 0.057
[1,   797] loss: 0.059
[1,   798] loss: 0.064
[1,   799] loss: 0.068
[1,   800] loss: 0.061
Model saved after epoch 0 and step 800
[1,   801] loss: 0.056
[1,   802] loss: 0.065
[1,   803] loss: 0.062
[1,   804] loss: 0.061
[1,   805] loss: 0.072
[1,   806] loss: 0.063
[1,   807] loss: 0.061
[1,   808] loss: 0.064
[1,   809] loss: 0.066
[1,   810] loss: 0.063
[1,   811] loss: 0.060
[1,   812] loss: 0.060
[1,   813] loss: 0.057
[1,   814] loss: 0.067
[1,   815] loss: 0.056
[1,   816] loss: 0.066
[1,   817] loss: 0.060
[1,   818] loss: 0.066
[1,   819] loss: 0.059
[1,   820] loss: 0.057
[1,   821] loss: 0.056
[1,   822] loss: 0.057
[1,   823] loss: 0.060
[1,   824] loss: 0.058
[1,   825] loss: 0.062
[1,   826] loss: 0.064
[1,   827] loss: 0.060
[1,   828] loss: 0.055
[1,   829] loss: 0.064
[1,   830] loss: 0.061
[1,   831] loss: 0.066
[1,   832] loss: 0.065
[1,   833] loss: 0.064
[1,   834] loss: 0.060
[1,   835] loss: 0.063
[1,   836] loss: 0.059
[1,   837] loss: 0.065
[1,   838] loss: 0.062
[1,   839] loss: 0.062
[1,   840] loss: 0.058
[1,   841] loss: 0.060
[1,   842] loss: 0.066
[1,   843] loss: 0.064
[1,   844] loss: 0.068
[1,   845] loss: 0.056
[1,   846] loss: 0.055
[1,   847] loss: 0.060
[1,   848] loss: 0.056
[1,   849] loss: 0.056
[1,   850] loss: 0.067
[1,   851] loss: 0.073
[1,   852] loss: 0.064
[1,   853] loss: 0.067
[1,   854] loss: 0.058
[1,   855] loss: 0.061
[1,   856] loss: 0.059
[1,   857] loss: 0.062
[1,   858] loss: 0.063
[1,   859] loss: 0.060
[1,   860] loss: 0.066
[1,   861] loss: 0.062
[1,   862] loss: 0.065
[1,   863] loss: 0.057
[1,   864] loss: 0.068
[1,   865] loss: 0.053
[1,   866] loss: 0.058
[1,   867] loss: 0.066
[1,   868] loss: 0.061
[1,   869] loss: 0.065
[1,   870] loss: 0.063
[1,   871] loss: 0.061
[1,   872] loss: 0.064
[1,   873] loss: 0.060
[1,   874] loss: 0.057
[1,   875] loss: 0.061
[1,   876] loss: 0.057
[1,   877] loss: 0.064
[1,   878] loss: 0.056
[1,   879] loss: 0.063
[1,   880] loss: 0.056
[1,   881] loss: 0.065
[1,   882] loss: 0.059
[1,   883] loss: 0.060
[1,   884] loss: 0.063
[1,   885] loss: 0.064
[1,   886] loss: 0.056
[1,   887] loss: 0.059
[1,   888] loss: 0.062
[1,   889] loss: 0.064
[1,   890] loss: 0.061
[1,   891] loss: 0.060
[1,   892] loss: 0.061
[1,   893] loss: 0.063
[1,   894] loss: 0.060
[1,   895] loss: 0.060
[1,   896] loss: 0.056
[1,   897] loss: 0.057
[1,   898] loss: 0.056
[1,   899] loss: 0.059
[1,   900] loss: 0.063
Model saved after epoch 0 and step 900
[1,   901] loss: 0.060
[1,   902] loss: 0.067
[1,   903] loss: 0.058
[1,   904] loss: 0.063
[1,   905] loss: 0.063
[1,   906] loss: 0.060
[1,   907] loss: 0.057
[1,   908] loss: 0.064
[1,   909] loss: 0.053
[1,   910] loss: 0.062
[1,   911] loss: 0.057
[1,   912] loss: 0.057
[1,   913] loss: 0.061
[1,   914] loss: 0.058
[1,   915] loss: 0.058
[1,   916] loss: 0.057
[1,   917] loss: 0.053
[1,   918] loss: 0.052
[1,   919] loss: 0.053
[1,   920] loss: 0.054
[1,   921] loss: 0.064
[1,   922] loss: 0.064
[1,   923] loss: 0.059
[1,   924] loss: 0.057
[1,   925] loss: 0.066
[1,   926] loss: 0.055
[1,   927] loss: 0.062
[1,   928] loss: 0.060
[1,   929] loss: 0.063
[1,   930] loss: 0.048
[1,   931] loss: 0.063
[1,   932] loss: 0.060
[1,   933] loss: 0.060
[1,   934] loss: 0.056
[1,   935] loss: 0.066
[1,   936] loss: 0.062
[1,   937] loss: 0.060
[1,   938] loss: 0.057
[1,   939] loss: 0.068
[1,   940] loss: 0.059
[1,   941] loss: 0.062
[1,   942] loss: 0.056
[1,   943] loss: 0.060
[1,   944] loss: 0.065
[1,   945] loss: 0.054
[1,   946] loss: 0.060
[1,   947] loss: 0.062
[1,   948] loss: 0.059
[1,   949] loss: 0.059
[1,   950] loss: 0.061
[1,   951] loss: 0.064
[1,   952] loss: 0.057
[1,   953] loss: 0.065
[1,   954] loss: 0.056
[1,   955] loss: 0.060
[1,   956] loss: 0.055
[1,   957] loss: 0.068
[1,   958] loss: 0.065
[1,   959] loss: 0.053
[1,   960] loss: 0.065
[1,   961] loss: 0.059
[1,   962] loss: 0.066
[1,   963] loss: 0.059
[1,   964] loss: 0.056
[1,   965] loss: 0.059
[1,   966] loss: 0.053
[1,   967] loss: 0.054
[1,   968] loss: 0.056
[1,   969] loss: 0.064
[1,   970] loss: 0.063
[1,   971] loss: 0.063
[1,   972] loss: 0.063
[1,   973] loss: 0.064
[1,   974] loss: 0.060
[1,   975] loss: 0.056
[1,   976] loss: 0.060
[1,   977] loss: 0.061
[1,   978] loss: 0.063
[1,   979] loss: 0.061
[1,   980] loss: 0.059
[1,   981] loss: 0.050
[1,   982] loss: 0.062
[1,   983] loss: 0.062
[1,   984] loss: 0.062
[1,   985] loss: 0.058
[1,   986] loss: 0.060
[1,   987] loss: 0.063
[1,   988] loss: 0.056
[1,   989] loss: 0.062
[1,   990] loss: 0.053
[1,   991] loss: 0.056
[1,   992] loss: 0.062
[1,   993] loss: 0.058
[1,   994] loss: 0.063
[1,   995] loss: 0.052
[1,   996] loss: 0.055
[1,   997] loss: 0.054
[1,   998] loss: 0.060
[1,   999] loss: 0.060
[1,  1000] loss: 0.062
Model saved after epoch 0 and step 1000
[1,  1001] loss: 0.056
[1,  1002] loss: 0.071
[1,  1003] loss: 0.059
[1,  1004] loss: 0.064
[1,  1005] loss: 0.059
[1,  1006] loss: 0.060
[1,  1007] loss: 0.054
[1,  1008] loss: 0.057
[1,  1009] loss: 0.059
[1,  1010] loss: 0.058
[1,  1011] loss: 0.056
[1,  1012] loss: 0.065
[1,  1013] loss: 0.060
[1,  1014] loss: 0.059
[1,  1015] loss: 0.059
[1,  1016] loss: 0.059
[1,  1017] loss: 0.057
[1,  1018] loss: 0.057
[1,  1019] loss: 0.057
[1,  1020] loss: 0.048
[1,  1021] loss: 0.061
[1,  1022] loss: 0.065
[1,  1023] loss: 0.060
[1,  1024] loss: 0.054
[1,  1025] loss: 0.057
[1,  1026] loss: 0.059
[1,  1027] loss: 0.063
[1,  1028] loss: 0.058
[1,  1029] loss: 0.057
[1,  1030] loss: 0.060
[1,  1031] loss: 0.060
[1,  1032] loss: 0.057
[1,  1033] loss: 0.061
[1,  1034] loss: 0.064
[1,  1035] loss: 0.061
[1,  1036] loss: 0.062
[1,  1037] loss: 0.058
[1,  1038] loss: 0.055
[1,  1039] loss: 0.062
[1,  1040] loss: 0.068
[1,  1041] loss: 0.059
[1,  1042] loss: 0.053
[1,  1043] loss: 0.065
[1,  1044] loss: 0.055
[1,  1045] loss: 0.058
[1,  1046] loss: 0.059
[1,  1047] loss: 0.063
[1,  1048] loss: 0.062
[1,  1049] loss: 0.059
[1,  1050] loss: 0.056
[1,  1051] loss: 0.058
[1,  1052] loss: 0.060
[1,  1053] loss: 0.057
[1,  1054] loss: 0.062
[1,  1055] loss: 0.063

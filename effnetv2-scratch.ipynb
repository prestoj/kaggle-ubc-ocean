{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d04a979-354f-4a91-ab13-f2e3f2f0d510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>is_tma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38366</td>\n",
       "      <td>LGSC</td>\n",
       "      <td>31951</td>\n",
       "      <td>21718</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63298</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>26067</td>\n",
       "      <td>20341</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54928</td>\n",
       "      <td>CC</td>\n",
       "      <td>36166</td>\n",
       "      <td>31487</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18813</td>\n",
       "      <td>CC</td>\n",
       "      <td>54671</td>\n",
       "      <td>32443</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63429</td>\n",
       "      <td>EC</td>\n",
       "      <td>67783</td>\n",
       "      <td>29066</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id label  image_width  image_height  is_tma\n",
       "0     38366  LGSC        31951         21718   False\n",
       "1     63298  HGSC        26067         20341   False\n",
       "2     54928    CC        36166         31487   False\n",
       "3     18813    CC        54671         32443   False\n",
       "4     63429    EC        67783         29066   False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"train-no-tma.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c1aff12-b7c1-4afd-8eac-4bddb40f7eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>is_tma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9658</td>\n",
       "      <td>CC</td>\n",
       "      <td>52900</td>\n",
       "      <td>45380</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12522</td>\n",
       "      <td>EC</td>\n",
       "      <td>46605</td>\n",
       "      <td>45511</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34845</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>42908</td>\n",
       "      <td>25840</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38585</td>\n",
       "      <td>LGSC</td>\n",
       "      <td>64822</td>\n",
       "      <td>30320</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23523</td>\n",
       "      <td>MC</td>\n",
       "      <td>74723</td>\n",
       "      <td>45387</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id label  image_width  image_height  is_tma\n",
       "0      9658    CC        52900         45380   False\n",
       "1     12522    EC        46605         45511   False\n",
       "2     34845  HGSC        42908         25840   False\n",
       "3     38585  LGSC        64822         30320   False\n",
       "4     23523    MC        74723         45387   False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = pd.read_csv(\"validation-no-tma.csv\")\n",
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82500098-49ea-4a7e-bb63-ce5130f954cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>is_tma</th>\n",
       "      <th>tile_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38366</td>\n",
       "      <td>LGSC</td>\n",
       "      <td>31951</td>\n",
       "      <td>21718</td>\n",
       "      <td>False</td>\n",
       "      <td>tiles/38366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63298</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>26067</td>\n",
       "      <td>20341</td>\n",
       "      <td>False</td>\n",
       "      <td>tiles/63298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54928</td>\n",
       "      <td>CC</td>\n",
       "      <td>36166</td>\n",
       "      <td>31487</td>\n",
       "      <td>False</td>\n",
       "      <td>tiles/54928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18813</td>\n",
       "      <td>CC</td>\n",
       "      <td>54671</td>\n",
       "      <td>32443</td>\n",
       "      <td>False</td>\n",
       "      <td>tiles/18813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63429</td>\n",
       "      <td>EC</td>\n",
       "      <td>67783</td>\n",
       "      <td>29066</td>\n",
       "      <td>False</td>\n",
       "      <td>tiles/63429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id label  image_width  image_height  is_tma    tile_path\n",
       "0     38366  LGSC        31951         21718   False  tiles/38366\n",
       "1     63298  HGSC        26067         20341   False  tiles/63298\n",
       "2     54928    CC        36166         31487   False  tiles/54928\n",
       "3     18813    CC        54671         32443   False  tiles/18813\n",
       "4     63429    EC        67783         29066   False  tiles/63429"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_image_path(image_id:int):\n",
    "    return os.path.join('tiles', str(image_id))\n",
    "\n",
    "train['tile_path'] = train['image_id'].apply(lambda x: get_image_path(x))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be030c5b-2cd9-42bd-bb04-5cfa17f53927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>is_tma</th>\n",
       "      <th>tile_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9658</td>\n",
       "      <td>CC</td>\n",
       "      <td>52900</td>\n",
       "      <td>45380</td>\n",
       "      <td>False</td>\n",
       "      <td>tiles/9658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12522</td>\n",
       "      <td>EC</td>\n",
       "      <td>46605</td>\n",
       "      <td>45511</td>\n",
       "      <td>False</td>\n",
       "      <td>tiles/12522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34845</td>\n",
       "      <td>HGSC</td>\n",
       "      <td>42908</td>\n",
       "      <td>25840</td>\n",
       "      <td>False</td>\n",
       "      <td>tiles/34845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38585</td>\n",
       "      <td>LGSC</td>\n",
       "      <td>64822</td>\n",
       "      <td>30320</td>\n",
       "      <td>False</td>\n",
       "      <td>tiles/38585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23523</td>\n",
       "      <td>MC</td>\n",
       "      <td>74723</td>\n",
       "      <td>45387</td>\n",
       "      <td>False</td>\n",
       "      <td>tiles/23523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id label  image_width  image_height  is_tma    tile_path\n",
       "0      9658    CC        52900         45380   False   tiles/9658\n",
       "1     12522    EC        46605         45511   False  tiles/12522\n",
       "2     34845  HGSC        42908         25840   False  tiles/34845\n",
       "3     38585  LGSC        64822         30320   False  tiles/38585\n",
       "4     23523    MC        74723         45387   False  tiles/23523"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation['tile_path'] = validation['image_id'].apply(lambda x: get_image_path(x))\n",
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d782638-2c6c-4b63-87b3-c7bf291bbde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the EfficientNetV2 model\n",
    "model_name = 'efficientnetv2_s'  # You can choose from different versions of EfficientNetV2 like 's', 'm', 'l'\n",
    "model = timm.create_model(model_name, pretrained=False)\n",
    "\n",
    "# Update the input size if necessary - EfficientNetV2 models can handle a range of input sizes\n",
    "model.default_cfg['input_size'] = (3, 224, 224)\n",
    "\n",
    "# Modify the classifier head to have 5 output classes\n",
    "# The name of the last linear layer could be different based on the model architecture\n",
    "# For EfficientNetV2 the last linear layer is named 'classifier' or 'head.fc'\n",
    "if hasattr(model, 'classifier') and isinstance(model.classifier, nn.Linear):\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, 5)\n",
    "elif hasattr(model, 'head') and hasattr(model.head, 'fc'):\n",
    "    model.head.fc = nn.Linear(model.head.fc.in_features, 5)\n",
    "else:\n",
    "    print(\"The model doesn't have a single linear classifier layer as expected\")\n",
    "    \n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9613dea-4edf-47cd-a042-5f3468b19d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "integer_to_label = {\n",
    "    0: 'HGSC',\n",
    "    1: 'CC',\n",
    "    2: 'EC',\n",
    "    3: 'LGSC',\n",
    "    4: 'MC',\n",
    "}\n",
    "\n",
    "label_to_integer = {\n",
    "    'HGSC': 0,\n",
    "    'CC': 1,\n",
    "    'EC': 2,\n",
    "    'LGSC': 3,\n",
    "    'MC': 4,\n",
    "}\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        for index, row in dataframe.iterrows():\n",
    "            folder_path = row['tile_path']\n",
    "            label = row['label']\n",
    "            if os.path.isdir(folder_path):  # Check if the folder_path is a valid directory\n",
    "                for image_name in os.listdir(folder_path):\n",
    "                    if image_name.lower().endswith('.png'):  # Check if the file is a PNG\n",
    "                        image_path = os.path.join(folder_path, image_name)\n",
    "                        self.image_paths.append(image_path)\n",
    "                        self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx])\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label_to_integer[label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daab3db2-8fff-4b14-83f9-608c256dea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.transforms import autoaugment\n",
    "\n",
    "# Define the image transformations - normalization values are usually model-specific, these are common for EfficientNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize the image to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "train_dataset = ImageDataset(dataframe=train, transform=transform)\n",
    "val_dataset = ImageDataset(dataframe=validation, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, num_workers=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, num_workers=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aa0e2bd-4c21-48a1-a0fe-5eb15fb556b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Get the root logger\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Optional: Remove all existing handlers from the logger\n",
    "for handler in logger.handlers[:]:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "# Set the logging level\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create a FileHandler and add it to the logger\n",
    "file_handler = logging.FileHandler('training_log_scratch_effnetv2_non_tma.txt')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Create a StreamHandler for stderr and add it to the logger\n",
    "stream_handler = logging.StreamHandler(sys.stderr)\n",
    "stream_handler.setLevel(logging.ERROR)  # Only log ERROR and CRITICAL messages to stderr\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9b938-9860-4147-be7e-f6f36938f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "initial_lr = 2e-3\n",
    "\n",
    "# Function for linear warmup\n",
    "def warmup_linear(step, warmup_steps=10000):\n",
    "    if step < warmup_steps:\n",
    "        return float(step) / float(max(1, warmup_steps))\n",
    "    progress = float(step - warmup_steps) / float(max(1, len(train_dataloader) - warmup_steps))\n",
    "    return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_lr, weight_decay=1e-5)\n",
    "\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda step: warmup_linear(step))\n",
    "\n",
    "# Calculate class weights\n",
    "class_counts = np.array([3521456, 1876772, 2126428, 589002, 1053114], dtype=np.float32) # These were derived by looking at the number of files in tile_path for each label\n",
    "# class_counts = np.array([703, 690, 631, 581, 706], dtype=np.float32) # These were derived by looking at the number of files in tile_path for each label\n",
    "class_weights = 1. / class_counts\n",
    "class_weights /= class_weights.sum()\n",
    "\n",
    "# Convert class weights to tensor\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Define the loss function with class weights\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "num_epochs = 1\n",
    "best_val_accuracy = 0.0\n",
    "step = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # set the model to training mode\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_dataloader, 0):\n",
    "        # Convert images to PIL format\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Linearly increase the learning rate\n",
    "        lr_scale = warmup_linear(step)\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = lr_scale * initial_lr\n",
    "            \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        logits_per_image = outputs\n",
    "        loss = criterion(logits_per_image, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        step += 1\n",
    "\n",
    "        logging.info('[%d, %5d] loss: %.3f' % (epoch + 1, step, loss.item()))\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            model.eval()\n",
    "\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_dataloader:\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.numpy()  # Convert labels to numpy array for later use in accuracy calculation\n",
    "\n",
    "                    outputs = model(images)\n",
    "                    logits_per_image = outputs\n",
    "                    probs = logits_per_image.softmax(dim=1)\n",
    "\n",
    "                    # Get predicted labels\n",
    "                    preds = torch.argmax(probs, dim=1).cpu().numpy()\n",
    "\n",
    "                    # Store predictions and labels\n",
    "                    all_preds.extend(preds)\n",
    "                    all_labels.extend(labels)\n",
    "                    \n",
    "                    if len(all_preds) > 10000:\n",
    "                        break\n",
    "        \n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(all_labels, all_preds)\n",
    "            logging.info(\"Validation Accuracy: %s\" % accuracy)\n",
    "            model.train()\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            # Assuming 'model' is defined\n",
    "            torch.save(model.state_dict(), f'effnetv2-scratch-non-tma-models/epoch_{epoch}_batch_{i}.pth')\n",
    "\n",
    "    # Save model after each epoch\n",
    "    torch.save(model.state_dict(), f'effnetv2-scratch-non-tma-models/model_epoch_{epoch+1}.pth')\n",
    "    logging.info(f'Model saved after epoch {epoch+1}')\n",
    "\n",
    "logging.info('Finished Training')\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
